{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import xgboost as xg\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getThreshold(y_test, probs, pos_label):\n",
    "    probs = probs.T[1]\n",
    "    actual = np.array([y_test == pos_label]).astype(int)[0]\n",
    "    resultsdf = pd.DataFrame(data = {'Actual':actual, 'Probability':probs})\n",
    "    tplist = []\n",
    "    tnlist = []\n",
    "    fplist = []\n",
    "    fnlist = []\n",
    "    threshlist = []\n",
    "    for thresh in np.linspace(0,1,num=51):\n",
    "        y_pred = probs > thresh\n",
    "        tplist.append((resultsdf['Actual'] * y_pred).sum())\n",
    "        tnlist.append(((1 - resultsdf['Actual']) * (1 - y_pred)).sum())\n",
    "        fplist.append(((1 - resultsdf['Actual']) * y_pred).sum())\n",
    "        fnlist.append((resultsdf['Actual'] * (1 - y_pred)).sum())\n",
    "        threshlist.append(thresh)\n",
    "    accdf = pd.DataFrame(data = {'Threshold':threshlist, 'TP':tplist, 'TN':tnlist, 'FP':fplist, 'FN':fnlist})\n",
    "    accdf['Accuracy'] = (accdf['TP'] + accdf['TN']) / (accdf['TP'] + accdf['FP'] + accdf['TN'] + accdf['FN'])\n",
    "    accdf['Precision'] = accdf['TP'] / (accdf['TP'] + accdf['FP'])\n",
    "    accdf['Recall / Sensitivity'] = accdf['TP'] / (accdf['TP'] + accdf['FN'])\n",
    "    accdf['Specificity'] = accdf['TN'] / (accdf['TN'] + accdf['TP'])\n",
    "    accdf['F1'] = 2*((accdf['Precision'] * accdf['Recall / Sensitivity']) / (accdf['Precision'] + accdf['Recall / Sensitivity']))\n",
    "    accdf['FN_Cost'] = accdf['FN']*500\n",
    "    accdf['FP_Cost'] = accdf['FP']*10\n",
    "    accdf['Tot_Cost'] = accdf['FN_Cost']+accdf['FP_Cost']\n",
    "    accdf['Cost_per_Obs'] = accdf['Tot_Cost']/(accdf['TP']+accdf['TN']+accdf['FP']+accdf['FN'])\n",
    "    return accdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load csv\n",
    "file_path = \"C:\\\\Users\\\\blgai\\\\OneDrive\\\\Documents\\\\School\\\\SMU\\\\Courses\\\\Spring 2021\\\\Quantifying The World\\\\Case Study 14\\\\Data\\\\final_project.csv\"\n",
    "#load Data into Pandas\n",
    "df_full = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x41</th>\n",
       "      <th>x42</th>\n",
       "      <th>x43</th>\n",
       "      <th>x44</th>\n",
       "      <th>x45</th>\n",
       "      <th>x46</th>\n",
       "      <th>x47</th>\n",
       "      <th>x48</th>\n",
       "      <th>x49</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.166563</td>\n",
       "      <td>-3.961588</td>\n",
       "      <td>4.621113</td>\n",
       "      <td>2.481908</td>\n",
       "      <td>-1.800135</td>\n",
       "      <td>0.804684</td>\n",
       "      <td>6.718751</td>\n",
       "      <td>-14.789997</td>\n",
       "      <td>-1.040673</td>\n",
       "      <td>-4.204950</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.497117</td>\n",
       "      <td>5.414063</td>\n",
       "      <td>-2.325655</td>\n",
       "      <td>1.674827</td>\n",
       "      <td>-0.264332</td>\n",
       "      <td>60.781427</td>\n",
       "      <td>-7.689696</td>\n",
       "      <td>0.151589</td>\n",
       "      <td>-8.040166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.149894</td>\n",
       "      <td>-0.585676</td>\n",
       "      <td>27.839856</td>\n",
       "      <td>4.152333</td>\n",
       "      <td>6.426802</td>\n",
       "      <td>-2.426943</td>\n",
       "      <td>40.477058</td>\n",
       "      <td>-6.725709</td>\n",
       "      <td>0.896421</td>\n",
       "      <td>0.330165</td>\n",
       "      <td>...</td>\n",
       "      <td>36.292790</td>\n",
       "      <td>4.490915</td>\n",
       "      <td>0.762561</td>\n",
       "      <td>6.526662</td>\n",
       "      <td>1.007927</td>\n",
       "      <td>15.805696</td>\n",
       "      <td>-4.896678</td>\n",
       "      <td>-0.320283</td>\n",
       "      <td>16.719974</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.321707</td>\n",
       "      <td>-1.429819</td>\n",
       "      <td>12.251561</td>\n",
       "      <td>6.586874</td>\n",
       "      <td>-5.304647</td>\n",
       "      <td>-11.311090</td>\n",
       "      <td>17.812850</td>\n",
       "      <td>11.060572</td>\n",
       "      <td>5.325880</td>\n",
       "      <td>-2.632984</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.368491</td>\n",
       "      <td>9.088864</td>\n",
       "      <td>-0.689886</td>\n",
       "      <td>-2.731118</td>\n",
       "      <td>0.754200</td>\n",
       "      <td>30.856417</td>\n",
       "      <td>-7.428573</td>\n",
       "      <td>-2.090804</td>\n",
       "      <td>-7.869421</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.245594</td>\n",
       "      <td>5.076677</td>\n",
       "      <td>-24.149632</td>\n",
       "      <td>3.637307</td>\n",
       "      <td>6.505811</td>\n",
       "      <td>2.290224</td>\n",
       "      <td>-35.111751</td>\n",
       "      <td>-18.913592</td>\n",
       "      <td>-0.337041</td>\n",
       "      <td>-5.568076</td>\n",
       "      <td>...</td>\n",
       "      <td>15.691546</td>\n",
       "      <td>-7.467775</td>\n",
       "      <td>2.940789</td>\n",
       "      <td>-6.424112</td>\n",
       "      <td>0.419776</td>\n",
       "      <td>-72.424569</td>\n",
       "      <td>5.361375</td>\n",
       "      <td>1.806070</td>\n",
       "      <td>-7.670847</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.273366</td>\n",
       "      <td>0.306326</td>\n",
       "      <td>-11.352593</td>\n",
       "      <td>1.676758</td>\n",
       "      <td>2.928441</td>\n",
       "      <td>-0.616824</td>\n",
       "      <td>-16.505817</td>\n",
       "      <td>27.532281</td>\n",
       "      <td>1.199715</td>\n",
       "      <td>-4.309105</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.911297</td>\n",
       "      <td>-5.229937</td>\n",
       "      <td>1.783928</td>\n",
       "      <td>3.957801</td>\n",
       "      <td>-0.096988</td>\n",
       "      <td>-14.085435</td>\n",
       "      <td>-0.208351</td>\n",
       "      <td>-0.894942</td>\n",
       "      <td>15.724742</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1         x2        x3        x4         x5         x6  \\\n",
       "0 -0.166563 -3.961588   4.621113  2.481908 -1.800135   0.804684   6.718751   \n",
       "1 -0.149894 -0.585676  27.839856  4.152333  6.426802  -2.426943  40.477058   \n",
       "2 -0.321707 -1.429819  12.251561  6.586874 -5.304647 -11.311090  17.812850   \n",
       "3 -0.245594  5.076677 -24.149632  3.637307  6.505811   2.290224 -35.111751   \n",
       "4 -0.273366  0.306326 -11.352593  1.676758  2.928441  -0.616824 -16.505817   \n",
       "\n",
       "          x7        x8        x9  ...        x41       x42       x43  \\\n",
       "0 -14.789997 -1.040673 -4.204950  ...  -1.497117  5.414063 -2.325655   \n",
       "1  -6.725709  0.896421  0.330165  ...  36.292790  4.490915  0.762561   \n",
       "2  11.060572  5.325880 -2.632984  ...  -0.368491  9.088864 -0.689886   \n",
       "3 -18.913592 -0.337041 -5.568076  ...  15.691546 -7.467775  2.940789   \n",
       "4  27.532281  1.199715 -4.309105  ... -13.911297 -5.229937  1.783928   \n",
       "\n",
       "        x44       x45        x46       x47       x48        x49  y  \n",
       "0  1.674827 -0.264332  60.781427 -7.689696  0.151589  -8.040166  0  \n",
       "1  6.526662  1.007927  15.805696 -4.896678 -0.320283  16.719974  0  \n",
       "2 -2.731118  0.754200  30.856417 -7.428573 -2.090804  -7.869421  0  \n",
       "3 -6.424112  0.419776 -72.424569  5.361375  1.806070  -7.670847  0  \n",
       "4  3.957801 -0.096988 -14.085435 -0.208351 -0.894942  15.724742  1  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000, 51)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x0     26\n",
       "x1     25\n",
       "x2     38\n",
       "x3     37\n",
       "x4     26\n",
       "x5     37\n",
       "x6     26\n",
       "x7     27\n",
       "x8     21\n",
       "x9     30\n",
       "x10    43\n",
       "x11    30\n",
       "x12    36\n",
       "x13    31\n",
       "x14    34\n",
       "x15    35\n",
       "x16    26\n",
       "x17    27\n",
       "x18    40\n",
       "x19    35\n",
       "x20    38\n",
       "x21    29\n",
       "x22    27\n",
       "x23    47\n",
       "x24    28\n",
       "x25    22\n",
       "x26    36\n",
       "x27    30\n",
       "x28    35\n",
       "x29    30\n",
       "x30    30\n",
       "x31    39\n",
       "x32    31\n",
       "x33    41\n",
       "x34    41\n",
       "x35    30\n",
       "x36    27\n",
       "x37    23\n",
       "x38    31\n",
       "x39    23\n",
       "x40    36\n",
       "x41    40\n",
       "x42    26\n",
       "x43    37\n",
       "x44    40\n",
       "x45    29\n",
       "x46    31\n",
       "x47    37\n",
       "x48    32\n",
       "x49    32\n",
       "y       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's check to see how many data points are missing by attribute\n",
    "len(df_full)-df_full.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x41</th>\n",
       "      <th>x42</th>\n",
       "      <th>x43</th>\n",
       "      <th>x44</th>\n",
       "      <th>x45</th>\n",
       "      <th>x46</th>\n",
       "      <th>x47</th>\n",
       "      <th>x48</th>\n",
       "      <th>x49</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159974.000000</td>\n",
       "      <td>159975.000000</td>\n",
       "      <td>159962.000000</td>\n",
       "      <td>159963.000000</td>\n",
       "      <td>159974.000000</td>\n",
       "      <td>159963.000000</td>\n",
       "      <td>159974.000000</td>\n",
       "      <td>159973.000000</td>\n",
       "      <td>159979.000000</td>\n",
       "      <td>159970.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>159960.000000</td>\n",
       "      <td>159974.000000</td>\n",
       "      <td>159963.000000</td>\n",
       "      <td>159960.000000</td>\n",
       "      <td>159971.000000</td>\n",
       "      <td>159969.000000</td>\n",
       "      <td>159963.000000</td>\n",
       "      <td>159968.000000</td>\n",
       "      <td>159968.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.001028</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>-1.150145</td>\n",
       "      <td>-0.024637</td>\n",
       "      <td>-0.000549</td>\n",
       "      <td>0.013582</td>\n",
       "      <td>-1.670670</td>\n",
       "      <td>-7.692795</td>\n",
       "      <td>-0.030540</td>\n",
       "      <td>0.005462</td>\n",
       "      <td>...</td>\n",
       "      <td>6.701076</td>\n",
       "      <td>-1.833820</td>\n",
       "      <td>-0.002091</td>\n",
       "      <td>-0.006250</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>-12.755395</td>\n",
       "      <td>0.028622</td>\n",
       "      <td>-0.000224</td>\n",
       "      <td>-0.674224</td>\n",
       "      <td>0.401231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.371137</td>\n",
       "      <td>6.340632</td>\n",
       "      <td>13.273480</td>\n",
       "      <td>8.065032</td>\n",
       "      <td>6.382293</td>\n",
       "      <td>7.670076</td>\n",
       "      <td>19.298665</td>\n",
       "      <td>30.542264</td>\n",
       "      <td>8.901185</td>\n",
       "      <td>6.355040</td>\n",
       "      <td>...</td>\n",
       "      <td>18.680196</td>\n",
       "      <td>5.110705</td>\n",
       "      <td>1.534952</td>\n",
       "      <td>4.164595</td>\n",
       "      <td>0.396621</td>\n",
       "      <td>36.608641</td>\n",
       "      <td>4.788157</td>\n",
       "      <td>1.935501</td>\n",
       "      <td>15.036738</td>\n",
       "      <td>0.490149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.592635</td>\n",
       "      <td>-26.278302</td>\n",
       "      <td>-59.394048</td>\n",
       "      <td>-35.476594</td>\n",
       "      <td>-28.467536</td>\n",
       "      <td>-33.822988</td>\n",
       "      <td>-86.354483</td>\n",
       "      <td>-181.506976</td>\n",
       "      <td>-37.691045</td>\n",
       "      <td>-27.980659</td>\n",
       "      <td>...</td>\n",
       "      <td>-82.167224</td>\n",
       "      <td>-27.933750</td>\n",
       "      <td>-6.876234</td>\n",
       "      <td>-17.983487</td>\n",
       "      <td>-1.753221</td>\n",
       "      <td>-201.826828</td>\n",
       "      <td>-21.086333</td>\n",
       "      <td>-8.490155</td>\n",
       "      <td>-65.791191</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.251641</td>\n",
       "      <td>-4.260973</td>\n",
       "      <td>-10.166536</td>\n",
       "      <td>-5.454438</td>\n",
       "      <td>-4.313118</td>\n",
       "      <td>-5.148130</td>\n",
       "      <td>-14.780146</td>\n",
       "      <td>-27.324771</td>\n",
       "      <td>-6.031058</td>\n",
       "      <td>-4.260619</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.804080</td>\n",
       "      <td>-5.162869</td>\n",
       "      <td>-1.039677</td>\n",
       "      <td>-2.812055</td>\n",
       "      <td>-0.266518</td>\n",
       "      <td>-36.428329</td>\n",
       "      <td>-3.216016</td>\n",
       "      <td>-1.320800</td>\n",
       "      <td>-10.931753</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.002047</td>\n",
       "      <td>0.004813</td>\n",
       "      <td>-1.340932</td>\n",
       "      <td>-0.031408</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.014118</td>\n",
       "      <td>-1.948594</td>\n",
       "      <td>-6.956789</td>\n",
       "      <td>-0.016840</td>\n",
       "      <td>0.006045</td>\n",
       "      <td>...</td>\n",
       "      <td>6.840110</td>\n",
       "      <td>-1.923754</td>\n",
       "      <td>-0.004385</td>\n",
       "      <td>-0.010484</td>\n",
       "      <td>0.001645</td>\n",
       "      <td>-12.982497</td>\n",
       "      <td>0.035865</td>\n",
       "      <td>-0.011993</td>\n",
       "      <td>-0.574410</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.248532</td>\n",
       "      <td>4.284220</td>\n",
       "      <td>7.871676</td>\n",
       "      <td>5.445179</td>\n",
       "      <td>4.306660</td>\n",
       "      <td>5.190749</td>\n",
       "      <td>11.446931</td>\n",
       "      <td>12.217071</td>\n",
       "      <td>5.972349</td>\n",
       "      <td>4.305734</td>\n",
       "      <td>...</td>\n",
       "      <td>19.266367</td>\n",
       "      <td>1.453507</td>\n",
       "      <td>1.033275</td>\n",
       "      <td>2.783274</td>\n",
       "      <td>0.269049</td>\n",
       "      <td>11.445443</td>\n",
       "      <td>3.268028</td>\n",
       "      <td>1.317703</td>\n",
       "      <td>9.651072</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.600849</td>\n",
       "      <td>27.988178</td>\n",
       "      <td>63.545653</td>\n",
       "      <td>38.906025</td>\n",
       "      <td>26.247812</td>\n",
       "      <td>35.550110</td>\n",
       "      <td>92.390605</td>\n",
       "      <td>149.150634</td>\n",
       "      <td>39.049831</td>\n",
       "      <td>27.377842</td>\n",
       "      <td>...</td>\n",
       "      <td>100.050432</td>\n",
       "      <td>22.668041</td>\n",
       "      <td>6.680922</td>\n",
       "      <td>19.069759</td>\n",
       "      <td>1.669205</td>\n",
       "      <td>150.859415</td>\n",
       "      <td>20.836854</td>\n",
       "      <td>8.226552</td>\n",
       "      <td>66.877604</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  x0             x1             x2             x3  \\\n",
       "count  159974.000000  159975.000000  159962.000000  159963.000000   \n",
       "mean       -0.001028       0.001358      -1.150145      -0.024637   \n",
       "std         0.371137       6.340632      13.273480       8.065032   \n",
       "min        -1.592635     -26.278302     -59.394048     -35.476594   \n",
       "25%        -0.251641      -4.260973     -10.166536      -5.454438   \n",
       "50%        -0.002047       0.004813      -1.340932      -0.031408   \n",
       "75%         0.248532       4.284220       7.871676       5.445179   \n",
       "max         1.600849      27.988178      63.545653      38.906025   \n",
       "\n",
       "                  x4             x5             x6             x7  \\\n",
       "count  159974.000000  159963.000000  159974.000000  159973.000000   \n",
       "mean       -0.000549       0.013582      -1.670670      -7.692795   \n",
       "std         6.382293       7.670076      19.298665      30.542264   \n",
       "min       -28.467536     -33.822988     -86.354483    -181.506976   \n",
       "25%        -4.313118      -5.148130     -14.780146     -27.324771   \n",
       "50%         0.000857       0.014118      -1.948594      -6.956789   \n",
       "75%         4.306660       5.190749      11.446931      12.217071   \n",
       "max        26.247812      35.550110      92.390605     149.150634   \n",
       "\n",
       "                  x8             x9  ...            x41            x42  \\\n",
       "count  159979.000000  159970.000000  ...  159960.000000  159974.000000   \n",
       "mean       -0.030540       0.005462  ...       6.701076      -1.833820   \n",
       "std         8.901185       6.355040  ...      18.680196       5.110705   \n",
       "min       -37.691045     -27.980659  ...     -82.167224     -27.933750   \n",
       "25%        -6.031058      -4.260619  ...      -5.804080      -5.162869   \n",
       "50%        -0.016840       0.006045  ...       6.840110      -1.923754   \n",
       "75%         5.972349       4.305734  ...      19.266367       1.453507   \n",
       "max        39.049831      27.377842  ...     100.050432      22.668041   \n",
       "\n",
       "                 x43            x44            x45            x46  \\\n",
       "count  159963.000000  159960.000000  159971.000000  159969.000000   \n",
       "mean       -0.002091      -0.006250       0.000885     -12.755395   \n",
       "std         1.534952       4.164595       0.396621      36.608641   \n",
       "min        -6.876234     -17.983487      -1.753221    -201.826828   \n",
       "25%        -1.039677      -2.812055      -0.266518     -36.428329   \n",
       "50%        -0.004385      -0.010484       0.001645     -12.982497   \n",
       "75%         1.033275       2.783274       0.269049      11.445443   \n",
       "max         6.680922      19.069759       1.669205     150.859415   \n",
       "\n",
       "                 x47            x48            x49              y  \n",
       "count  159963.000000  159968.000000  159968.000000  160000.000000  \n",
       "mean        0.028622      -0.000224      -0.674224       0.401231  \n",
       "std         4.788157       1.935501      15.036738       0.490149  \n",
       "min       -21.086333      -8.490155     -65.791191       0.000000  \n",
       "25%        -3.216016      -1.320800     -10.931753       0.000000  \n",
       "50%         0.035865      -0.011993      -0.574410       0.000000  \n",
       "75%         3.268028       1.317703       9.651072       1.000000  \n",
       "max        20.836854       8.226552      66.877604       1.000000  \n",
       "\n",
       "[8 rows x 46 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's check the 5 number summary of the data\n",
    "df_full.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's drop records containing missing values\n",
    "df_full = df_full.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158392, 51)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after dropping records with missing data we end up with 158392 records out of 160000\n",
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98995"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we still have 98.99% of the data, only removing 1.1% of the data with missing values\n",
    "len(df_full)/160000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x0     float64\n",
       "x1     float64\n",
       "x2     float64\n",
       "x3     float64\n",
       "x4     float64\n",
       "x5     float64\n",
       "x6     float64\n",
       "x7     float64\n",
       "x8     float64\n",
       "x9     float64\n",
       "x10    float64\n",
       "x11    float64\n",
       "x12    float64\n",
       "x13    float64\n",
       "x14    float64\n",
       "x15    float64\n",
       "x16    float64\n",
       "x17    float64\n",
       "x18    float64\n",
       "x19    float64\n",
       "x20    float64\n",
       "x21    float64\n",
       "x22    float64\n",
       "x23    float64\n",
       "x24     object\n",
       "x25    float64\n",
       "x26    float64\n",
       "x27    float64\n",
       "x28    float64\n",
       "x29     object\n",
       "x30     object\n",
       "x31    float64\n",
       "x32     object\n",
       "x33    float64\n",
       "x34    float64\n",
       "x35    float64\n",
       "x36    float64\n",
       "x37     object\n",
       "x38    float64\n",
       "x39    float64\n",
       "x40    float64\n",
       "x41    float64\n",
       "x42    float64\n",
       "x43    float64\n",
       "x44    float64\n",
       "x45    float64\n",
       "x46    float64\n",
       "x47    float64\n",
       "x48    float64\n",
       "x49    float64\n",
       "y        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can see that there are categorical variables\n",
    "df_full.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove percent sign and convert to float\n",
    "df_full['x32'] = df_full['x32'].str.rstrip('%').astype('float') / 100.0\n",
    "\n",
    "#remove dollar sign and convert to float\n",
    "df_full['x37'] = df_full['x37'].str.lstrip('$').astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish which columns we want to encode - the categoricals we identified above\n",
    "from collections import Counter\n",
    "\n",
    "#get the list of all column names\n",
    "all_columns = df_full.columns.tolist()\n",
    "#select the columns to encode\n",
    "columns_to_encode = ['x24','x29','x30']\n",
    "#remove columns to encode from list of all columns\n",
    "remaining = Counter(all_columns) - Counter(columns_to_encode)\n",
    "#now we also have the columns we don't want to encode\n",
    "columns_no_change = list(remaining.elements())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode the categorical features\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "df_existing = df_full[columns_no_change]\n",
    "existing_cols = df_existing.to_numpy()\n",
    "\n",
    "#encoder \n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "\n",
    "#ohe separate columns\n",
    "encoded_columns = ohe.fit_transform(df_full[columns_to_encode])\n",
    "\n",
    "#concatenate processed columns back together into np_full\n",
    "np_full = np.concatenate([encoded_columns,existing_cols],axis=1)\n",
    "\n",
    "#get the column names back to the dataframe\n",
    "df1 = pd.DataFrame(np_full)\n",
    "feature_names = ohe.get_feature_names().tolist()\n",
    "col_names = feature_names+columns_no_change\n",
    "df1.columns = col_names\n",
    "df_enc = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get training and test data using a 70:30 split\n",
    "train_set = df_enc.sample(frac=0.7, random_state=100)\n",
    "test_set = df_enc[~df_enc.isin(train_set)].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0_america</th>\n",
       "      <th>x0_asia</th>\n",
       "      <th>x0_euorpe</th>\n",
       "      <th>x1_Apr</th>\n",
       "      <th>x1_Aug</th>\n",
       "      <th>x1_Dev</th>\n",
       "      <th>x1_Feb</th>\n",
       "      <th>x1_January</th>\n",
       "      <th>x1_July</th>\n",
       "      <th>x1_Jun</th>\n",
       "      <th>...</th>\n",
       "      <th>x41</th>\n",
       "      <th>x42</th>\n",
       "      <th>x43</th>\n",
       "      <th>x44</th>\n",
       "      <th>x45</th>\n",
       "      <th>x46</th>\n",
       "      <th>x47</th>\n",
       "      <th>x48</th>\n",
       "      <th>x49</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153031</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.066063</td>\n",
       "      <td>-0.457926</td>\n",
       "      <td>1.667307</td>\n",
       "      <td>-0.551113</td>\n",
       "      <td>-0.201617</td>\n",
       "      <td>10.801960</td>\n",
       "      <td>-3.938598</td>\n",
       "      <td>0.694430</td>\n",
       "      <td>-0.285937</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53185</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.296005</td>\n",
       "      <td>-0.970483</td>\n",
       "      <td>0.031527</td>\n",
       "      <td>-8.783706</td>\n",
       "      <td>-0.133021</td>\n",
       "      <td>-29.467004</td>\n",
       "      <td>0.311234</td>\n",
       "      <td>2.691652</td>\n",
       "      <td>14.490999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149956</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.572387</td>\n",
       "      <td>-10.301428</td>\n",
       "      <td>0.339596</td>\n",
       "      <td>2.670589</td>\n",
       "      <td>0.085581</td>\n",
       "      <td>-90.398156</td>\n",
       "      <td>2.040747</td>\n",
       "      <td>0.601428</td>\n",
       "      <td>-8.797383</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131462</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.440283</td>\n",
       "      <td>-1.156105</td>\n",
       "      <td>0.304508</td>\n",
       "      <td>-9.080351</td>\n",
       "      <td>0.383922</td>\n",
       "      <td>2.281883</td>\n",
       "      <td>-6.345140</td>\n",
       "      <td>0.791787</td>\n",
       "      <td>-1.197098</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37557</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.870788</td>\n",
       "      <td>-2.228647</td>\n",
       "      <td>1.363441</td>\n",
       "      <td>3.850160</td>\n",
       "      <td>0.275508</td>\n",
       "      <td>-72.481023</td>\n",
       "      <td>2.199502</td>\n",
       "      <td>1.766310</td>\n",
       "      <td>-17.309968</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        x0_america  x0_asia  x0_euorpe  x1_Apr  x1_Aug  x1_Dev  x1_Feb  \\\n",
       "153031         0.0      1.0        0.0     0.0     0.0     0.0     0.0   \n",
       "53185          0.0      1.0        0.0     0.0     0.0     0.0     0.0   \n",
       "149956         1.0      0.0        0.0     0.0     0.0     0.0     0.0   \n",
       "131462         0.0      1.0        0.0     0.0     0.0     0.0     0.0   \n",
       "37557          0.0      1.0        0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "        x1_January  x1_July  x1_Jun  ...        x41        x42       x43  \\\n",
       "153031         0.0      1.0     0.0  ...  -5.066063  -0.457926  1.667307   \n",
       "53185          0.0      1.0     0.0  ...  25.296005  -0.970483  0.031527   \n",
       "149956         0.0      0.0     1.0  ...   9.572387 -10.301428  0.339596   \n",
       "131462         0.0      0.0     0.0  ... -11.440283  -1.156105  0.304508   \n",
       "37557          0.0      0.0     1.0  ...   5.870788  -2.228647  1.363441   \n",
       "\n",
       "             x44       x45        x46       x47       x48        x49    y  \n",
       "153031 -0.551113 -0.201617  10.801960 -3.938598  0.694430  -0.285937  0.0  \n",
       "53185  -8.783706 -0.133021 -29.467004  0.311234  2.691652  14.490999  0.0  \n",
       "149956  2.670589  0.085581 -90.398156  2.040747  0.601428  -8.797383  0.0  \n",
       "131462 -9.080351  0.383922   2.281883 -6.345140  0.791787  -1.197098  1.0  \n",
       "37557   3.850160  0.275508 -72.481023  2.199502  1.766310 -17.309968  0.0  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x0_america    float64\n",
       "x0_asia       float64\n",
       "x0_euorpe     float64\n",
       "x1_Apr        float64\n",
       "x1_Aug        float64\n",
       "               ...   \n",
       "x46           float64\n",
       "x47           float64\n",
       "x48           float64\n",
       "x49           float64\n",
       "y             float64\n",
       "Length: 68, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0_america</th>\n",
       "      <th>x0_asia</th>\n",
       "      <th>x0_euorpe</th>\n",
       "      <th>x1_Apr</th>\n",
       "      <th>x1_Aug</th>\n",
       "      <th>x1_Dev</th>\n",
       "      <th>x1_Feb</th>\n",
       "      <th>x1_January</th>\n",
       "      <th>x1_July</th>\n",
       "      <th>x1_Jun</th>\n",
       "      <th>...</th>\n",
       "      <th>x41</th>\n",
       "      <th>x42</th>\n",
       "      <th>x43</th>\n",
       "      <th>x44</th>\n",
       "      <th>x45</th>\n",
       "      <th>x46</th>\n",
       "      <th>x47</th>\n",
       "      <th>x48</th>\n",
       "      <th>x49</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.368491</td>\n",
       "      <td>9.088864</td>\n",
       "      <td>-0.689886</td>\n",
       "      <td>-2.731118</td>\n",
       "      <td>0.754200</td>\n",
       "      <td>30.856417</td>\n",
       "      <td>-7.428573</td>\n",
       "      <td>-2.090804</td>\n",
       "      <td>-7.869421</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.911297</td>\n",
       "      <td>-5.229937</td>\n",
       "      <td>1.783928</td>\n",
       "      <td>3.957801</td>\n",
       "      <td>-0.096988</td>\n",
       "      <td>-14.085435</td>\n",
       "      <td>-0.208351</td>\n",
       "      <td>-0.894942</td>\n",
       "      <td>15.724742</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.267232</td>\n",
       "      <td>-0.675888</td>\n",
       "      <td>-2.560935</td>\n",
       "      <td>1.326146</td>\n",
       "      <td>0.444997</td>\n",
       "      <td>-20.942887</td>\n",
       "      <td>-3.141996</td>\n",
       "      <td>-1.608473</td>\n",
       "      <td>7.169219</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.027775</td>\n",
       "      <td>-3.903575</td>\n",
       "      <td>1.938380</td>\n",
       "      <td>-5.395413</td>\n",
       "      <td>0.459957</td>\n",
       "      <td>-77.491333</td>\n",
       "      <td>0.754309</td>\n",
       "      <td>-0.442017</td>\n",
       "      <td>-21.824215</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.341481</td>\n",
       "      <td>-8.749303</td>\n",
       "      <td>-2.927836</td>\n",
       "      <td>-4.118254</td>\n",
       "      <td>0.790090</td>\n",
       "      <td>-95.290753</td>\n",
       "      <td>-2.076083</td>\n",
       "      <td>0.841078</td>\n",
       "      <td>-16.644318</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    x0_america  x0_asia  x0_euorpe  x1_Apr  x1_Aug  x1_Dev  x1_Feb  \\\n",
       "2          0.0      1.0        0.0     0.0     0.0     0.0     0.0   \n",
       "4          0.0      1.0        0.0     0.0     0.0     0.0     0.0   \n",
       "9          0.0      1.0        0.0     0.0     0.0     0.0     0.0   \n",
       "10         0.0      1.0        0.0     0.0     0.0     0.0     0.0   \n",
       "11         1.0      0.0        0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "    x1_January  x1_July  x1_Jun  ...        x41       x42       x43       x44  \\\n",
       "2          0.0      1.0     0.0  ...  -0.368491  9.088864 -0.689886 -2.731118   \n",
       "4          0.0      1.0     0.0  ... -13.911297 -5.229937  1.783928  3.957801   \n",
       "9          0.0      0.0     1.0  ...  19.267232 -0.675888 -2.560935  1.326146   \n",
       "10         0.0      1.0     0.0  ...   5.027775 -3.903575  1.938380 -5.395413   \n",
       "11         0.0      1.0     0.0  ... -13.341481 -8.749303 -2.927836 -4.118254   \n",
       "\n",
       "         x45        x46       x47       x48        x49    y  \n",
       "2   0.754200  30.856417 -7.428573 -2.090804  -7.869421  0.0  \n",
       "4  -0.096988 -14.085435 -0.208351 -0.894942  15.724742  1.0  \n",
       "9   0.444997 -20.942887 -3.141996 -1.608473   7.169219  1.0  \n",
       "10  0.459957 -77.491333  0.754309 -0.442017 -21.824215  1.0  \n",
       "11  0.790090 -95.290753 -2.076083  0.841078 -16.644318  0.0  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x0_america    float64\n",
       "x0_asia       float64\n",
       "x0_euorpe     float64\n",
       "x1_Apr        float64\n",
       "x1_Aug        float64\n",
       "               ...   \n",
       "x46           float64\n",
       "x47           float64\n",
       "x48           float64\n",
       "x49           float64\n",
       "y               int64\n",
       "Length: 68, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = test_set.astype({'y': 'int64'})\n",
    "test_set.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158392"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set) + len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish our x and y training and test data\n",
    "X_train = train_set.iloc[:, 0:67].values # returns the data; excluding the target\n",
    "Y_train = train_set.iloc[:, -1].values # returns the target only\n",
    "X_test = test_set.iloc[:, 0:67].values # returns the data; excluding the target\n",
    "Y_test = test_set.iloc[:, -1].values # returns the target only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establish Baseline Model and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement simple model with minimal hyperparameters\n",
    "xgb_c = xg.XGBClassifier(importance_type='gain', max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:50:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_c.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = xgb_c.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26742,  1750],\n",
       "       [ 2331, 16695]], dtype=int64)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive: 16695\n",
      "False Positive: 1750\n",
      "False Negative: 2331\n",
      "True Negative: 26742\n",
      "=======================\n",
      "Accuracy: 0.9141167557557136\n",
      "TPR: 0.8774834437086093\n",
      "FPR: 0.06142074968412186\n",
      "Precision: 0.905123339658444\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(Y_test,Y_pred).ravel()\n",
    "print(\"True Positive: {}\".format(tp))\n",
    "print(\"False Positive: {}\".format(fp))\n",
    "print(\"False Negative: {}\".format(fn))\n",
    "print(\"True Negative: {}\".format(tn))\n",
    "print(\"=======================\")\n",
    "print(\"Accuracy: {}\".format((tp+tn)/(tp+tn+fp+fn)))\n",
    "print(\"TPR: {}\".format(tp/(tp+fn)))\n",
    "print(\"FPR: {}\".format(fp/(fp+tn)))\n",
    "print(\"Precision: {}\".format(tp/(tp+fp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "#Set up the parameters for grid search\n",
    "parameters = {'learning_rate' : [0.05,0.3],\n",
    "              'n_estimators' : [50,75,100],\n",
    "              'max_depth' : [5,7,9],\n",
    "              'gamma' : [.5,1,5],\n",
    "              'colsample_bytree' : [.075,1]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "xgb_c = xg.XGBClassifier()\n",
    "parameter_combo = 5\n",
    "kf = KFold(n_splits=3,shuffle=True,random_state=0)\n",
    "random_search = RandomizedSearchCV(xgb_c, param_distributions=parameters, n_iter=parameter_combo, cv=kf.split(X_train,Y_train) ,verbose=False, random_state=45)\n",
    "%time random_search.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0.5, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.3, max_delta_step=0, max_depth=9,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=75, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "print(random_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9289012753215361\n"
     ]
    }
   ],
   "source": [
    "print(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the best model\n",
    "xgb_c = xg.XGBClassifier(colsample_bytree=1, gamma=0.5, learning_rate=0.3, max_depth=9, n_estimators=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0.5, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.3, max_delta_step=0, max_depth=9,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=75, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_c.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = xgb_c.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive: 17256\n",
      "False Positive: 1368\n",
      "False Negative: 1770\n",
      "True Negative: 27124\n",
      "=======================\n",
      "Accuracy: 0.9339618670819478\n",
      "TPR: 0.9069694102806686\n",
      "FPR: 0.04801347746735926\n",
      "Precision: 0.9265463917525774\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(Y_test,Y_pred).ravel()\n",
    "print(\"True Positive: {}\".format(tp))\n",
    "print(\"False Positive: {}\".format(fp))\n",
    "print(\"False Negative: {}\".format(fn))\n",
    "print(\"True Negative: {}\".format(tn))\n",
    "print(\"=======================\")\n",
    "print(\"Accuracy: {}\".format((tp+tn)/(tp+tn+fp+fn)))\n",
    "print(\"TPR: {}\".format(tp/(tp+fn)))\n",
    "print(\"FPR: {}\".format(fp/(fp+tn)))\n",
    "print(\"Precision: {}\".format(tp/(tp+fp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost of False Positives: $13680\n",
      "Cost of False Negatives: $885000\n",
      "Total Cost: $898680\n"
     ]
    }
   ],
   "source": [
    "fp_cost = fp*10\n",
    "fn_cost = fn*500\n",
    "print(\"Cost of False Positives: ${}\".format(fp_cost))\n",
    "print(\"Cost of False Negatives: ${}\".format(fn_cost))\n",
    "print(\"Total Cost: ${}\".format(fp_cost+fn_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9799708292068876"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "Y_score = xgb_c.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, Y_score, pos_label=2)\n",
    "roc_auc_score(Y_test,Y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbUAAAEfCAYAAADGLVhVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABOPUlEQVR4nO3deVxUVf/A8c/MsCuCIuACgrggkohCLlCimJq7uWuL4q5oi/q4/CqXshTNykzNJepxfXLBrc1KSVHcHhU161FyX0IUBRRZhJnfH8TkMAwOyMCA3/frxSvvvefe+51D3O+cc889V5GcnKxBCCGEqACUZR2AEEIIUVIkqQkhhKgwJKkJIYSoMCSpCSGEqDAkqQkhhKgwJKkJIYSoMCSpCSGEqDAkqQkhhKgwJKk9Rnx8fFmHYFakPvRJneiS+tAl9aHPlHUiSU0IIUSFIUlNCCFEhSFJTQghRIVRpkntwIEDDBw4EB8fHxwdHVm3bt1j9zlz5gxdunShRo0a+Pj4EBERgUYjczILIYQo46SWlpZG48aNmTdvHra2to8tn5qayksvvYSLiwt79uxh3rx5LF68mM8//7wUohVCCGHuLMry5B07dqRjx44AjBs37rHlN23aRHp6OsuWLcPW1pbGjRtz7tw5li5dyvjx41EoFKYOWQjxFNBoNKg1oOHvHw2PLP+zTf33+kf3y9uHv/dLygKH9Bw0mkfW/73tn39r/vn3I/s+2gelWz7v3xq98nlxPcjWYK1SaD/Lo/vmldGg0dvv0TKafGWupeXgbKPUOZbaQHm13rlyP2ftSipqFfH3URRlmtSK6siRI7Ru3VqnVde+fXs++OADLl++jKenZ9kFJyosjUZDlhrSszWoNRpyNJCtgWy1hmw1nL2vIPPOQ7LVuRePbE3u+sR0NTYWoFIoHvnj1uj8keddbNQajd4FIO+/Z5Mf4lZJhYVSQY5GQ44acv6+aKjVufHkaODh3/Hk/H0Ryy3zz781GsjM0bDzcjovutvknpd/Ltjqv8trl/Ni0Gi4fD+H/yVn06amtfbCnRcf2nK5+6enW2P9v0SdC6T673rUaOD35GwAGjhY6F00H72g8sgyPHLB5NHlgi7CefvqHjc1K3eLrUqhPY5ustJNUCXHDo4kmOLA5VIndxvmeJju+OUqqSUmJlKrlm6Od3Z21m6TpFbxqDUaMnI0ZOZAapaaLLWGtIcaEtPVKBXw252HONsqeajOvajnJZ+MHA0PczRkqXP3Tc/RkK3W8FAN+/7KxM5CQb0qFmSpNVy9n8O1tBwaOFjwUK3hVrqatGwNVn93zmepHxelLcQlmroqStR/zqcXa799f2UaUUoF9x8+tlR8SnaxYnhS6TlyD74smXoMRLlKaoBeF2NeBRXW9fikD/rJw5O6DNVHphpuZipIy4Gr6UpslH+3aP7+yVRDplrBQ3Xu8kO1gtRsSM5WkJadu9+JVBW2ytyEkqmGDLVpupTvZOZ2peh8rnwX2ccnMyFEUd1PewA82XW1QYMGBreVq6Tm4uJCYqLuN+Lbt28D/7TYClJYBTxOfHz8E+1fXmk0Gu5kqrnxQM31tGzSszXce6hhx9nb3FPakZieg6e9BXcy1ZxMevy38qJIVytIl4QiypgCUChy/6tU/LOsRKFdrwDuZ+d+sXa0yv0ClrtNQd7XMbU6BwuV6pFtusfX/pt/9tfGUGj5R8so9MrfTM8hJUuDb1ULlAqFwc+Td26lIt/xFbkjCRX59t33VybulVV4O1r+vb3wOspbz9/H861mCSSY7LparpJaixYtmDVrFhkZGdjY5N4TiI6OpmbNmnh4mLCTtoJJzlRz+s5DrqXlcObOQ9Ky1dx/mHuvJUsNNWyVJKaryS6wl8ACyALg4r2cggpUSBYKtPVR3UaJhSL3XplKCQlp2WRpFDxTzRJLZW5ZC6VC2z2alQPBNawe+aNX6Pyx511MtBcW9C86fyRnY6WEZ6pZolLkllPmxaAA1d/LVioFFn+vU2p/FH+X/Wef86nZ1LW3wM7in2PlnVf5SHzan78vUrfSc6hdSaVzoVPm+++1q9fwqOOue9F85Lh5F91sjQZblULnwvpo+Ty6F99/6g+99br/pYDyABbKvM+ryHchfvQYJddD8LR+MS5MfLzp7jGWaVK7f/8+Fy5cAECtVnPt2jVOnTpF1apVcXd3Z/bs2Rw7dowdO3YA0LdvXyIiIhg3bhyTJ0/mzz//5NNPP2XKlCky8rEANx/kcDYlmwup2ZxLecjSM2lG7XfjgXk1k6xVuTf3rVUKbqarsVUpqFtFxe93s+nkbsPBhExa17DGvZIKSyXYqBTYWCiwUiqwVIK1SoGthQJLpQLLvxOOhtxBE7UrqbTlcjRQzVqJpTI3OVgqFdiqFFipci/IhshFS1fVFDUNnK3KOgzxlCrTpHbixAm6d++uXZ47dy5z585l0KBBLFu2jISEBC5evKjd7uDgwNatW5k8eTLt2rXD0dGR8PBwxo8fXxbhm5XkTDW/3X3IL9cyuHgvm+2XMsosFitl7v2oyhYKqtsqaeZkhaUKbZKwVimw+jtxVLFSUtVKgYOVkkqWChytlFS2VOBorcTm77KWSvnCIoQwTpkmteeff57k5GSD25ctW6a3ztfXlx9++MGEUZUPl+5ls/lCOjfScjiUmMnvd0t+JFkVSwXVbJQ8zIHrD3IYUM8W64xUPFydSM1S41ZZRZNqllS3UWJvqaS6jRKVJCAhRBkqV/fUnnYXU7PZdOEBWy6kc7YEhkOH1LTG1U5Jk6qWOForqWqtxMVWiYOVEvfKKuws9CeciY9PokED+yc+txBCmIIkNTOX8CCHDX8+YPOFB5wpYmtMqQA7lYKQWtY0crTA29ESn6qWNHK0kC49IUSFJEnNDKVna/jm/APejE0u0n5ulVT4VrOkqpWC3nXtCKlljbVKkpcQ4ukhSc2M7L2RSc9dt40u72Cl4EV3G1q6WNPD04bqNioTRieEEOZPkloZu/dQzddn01h25r5RQ+mfdbakm4ctXevYUN/BshQiFEKI8kOSWhm5kZbDotP3WH3ugVFz0Y30qcTrz1TGvbL8yoQQwhC5Qpayh2oNESfusfjMPTIfMyGHi62SnS9Wx9tRWmRCCGEMSWql6L+3shgXc5dzhQzHb1vLmlE+lejsbiOzpAghRBFJUislX59NMzia0UoJo3wqM863MrUqyWAPIYQoLklqJpaj1vBmbDJr4h/obbO3VDDOtzIT/exl6L0QQpQASWompNZoGLQ7iZ+u6b9YsbWrFZFtq1HTTlpmQghRUiSpmYhGo2FszN0CE9rbzeyZ3NRe7pkJIUQJk6RmAhqNhjdik/nmfLrOegcrBUufq0pXD9syikwIISo2SWom8PKeO3x/RffVL07WSra/WJ1nqsnwfCGEMBX9adjFE1n5x329hFbZQsE2SWhCCGFyktRK0NX72Uw7nKKzzlIJ33auThNJaEIIYXKS1EqIRqNhxN675J/xanW7avhXl1fbCyFEaZCkVkIWnrrP4cQsnXXDvCvRuY4MChFCiNIiSa0EpD1U89HJVJ11rV2tWNDKoYwiEkKIp5MktRLw1sFkMvJNTvxZsCMqebu0EEKUKklqTyg9W8PGfM+jvdLAjgbyrjMhhCh1ktSe0OpzaXrr/q9ZlTKIRAghhCS1J5CerWHOcd17aYHOljLTvhBClBFJak9g9bk07j3UHcO/ob1TGUUjhBBCkloxqTUaPj19T2fdmMaVcLaVVpoQQpQVSWrFtPKPNP56oNYuK4AxjSuXXUBCCCGKl9SuXbtGXFwc9+/fL+l4yo0Vf+h+9p6etnjay/zQQghRloqU1L799luaN2+On58foaGhHDt2DICkpCSCgoLYuXOnSYI0NylZas6n6j6YNtTbroyiEUIIkcfopLZr1y5ee+01qlevztSpU9Fo/hkg4eTkhJubG+vXrzdJkOZmxe/6LdSQmtZlEIkQQohHGZ3U5s+fT8uWLfnpp58YOXKk3vZnn32W06dPl2hw5mrrJd2HrUc2qiRvsRZCCDNgdFL7/fff6d27t8Htrq6u3L59u0SCMmcPstX8fjdbZ103eZO1EEKYBaOTmpWVFZmZmQa3X716lSpVKv5MGodv6s7Er1JAm5ryahkhhDAHRie1Vq1asXXr1gK3paamsm7dOp5//vkiB7Bq1Sr8/PxwdXUlJCSE2NjYQsvv3r2bDh064ObmhpeXF4MGDeLPP/8s8nmL68gt3aT2Qm1r6XoUQggzYXRSmzZtGmfOnKFXr1788MMPAJw6dYrIyEhCQkJITU1lypQpRTp5VFQU06ZNY9KkSezbt48WLVrQr18/rl69WmD5S5cuMXjwYFq3bs2+ffvYtm0bGRkZ9OvXr0jnfRJLftMdJBJa26bUzi2EEKJwRie1Zs2asXnzZq5fv8748eMBmDFjBpMmTUKlUrF582a8vb2LdPIlS5YwePBghgwZgre3NwsWLMDV1ZXIyMgCy588eZKHDx8yc+ZMvLy88PPz46233uLixYskJSUV6dzFodZoSM03LVZILRn1KIQQ5qJITws/99xzHD16lNOnT3P+/HnUajV169bF39+/yF1wWVlZxMXFMWHCBJ31oaGhHD58uMB9/P39sbS0ZPXq1bz22ms8ePCADRs20Lx5c5ycTD/n4p8p2XrrvB3kgWshhDAXRl+RN2zYQFBQEB4eHjRp0oQmTZrobL98+TKxsbEMGjTIqOMlJSWRk5ODs7OzznpnZ2cSExML3MfDw4OtW7cydOhQJk+ejFqtxs/Pj82bNxd6rvj4eKNietz+0bdVgG7LrDTv55mLJ63PikjqRJfUhy6pD31PUicNGjQwuM3opBYeHs7y5cvx8PAocPuxY8cIDw83Oqnlyd/C02g0Blt9N2/eZMKECQwcOJA+ffpw//59PvzwQ4YOHcrOnTtRKgvuTS2sAh4nPj5eu/+QMzeBf1prLZytaNCgdrGPXR49Wh8il9SJLqkPXVIf+kxZJ0YntUdnEClIeno6KpXxM9Q7OTmhUqn0WmW3b9/Wa73lWblyJXZ2drz33nvadStWrMDX15fDhw/TunVro89fHPmfT+tSRwaJCCGEOSk0qV29epUrV65ol8+dO8eBAwf0yiUnJ/PVV18ZbMUVxMrKCn9/f6Kjo+nVq5d2fXR0ND169Chwn4ISZ96yWq0uaBeTalzVstTPKYQQwrBCk9q6deuIiIhAoVCgUChYuHAhCxcu1Cun0WhQKpUsWrSoSCcPDw9n9OjRBAQE0LJlSyIjI0lISCAsLAyA2bNnc+zYMXbs2AFAx44dWbp0KfPmzaNfv37cu3eP999/Hzc3N/z9/Yt07qJKysjRW9eutox8FEIIc1JoUuvZsycNGzZEo9EwYsQIRowYodfFp1AosLOzo2nTptSoUaNIJ+/duzd37txhwYIF3Lx5Ex8fHzZu3EidOnUASEhI4OLFi9ryISEhrFq1ikWLFrF48WJsbGwIDAxk8+bNVKpUqUjnLqrYfDOJAFgq5aFrIYQwJ4UmNR8fH3x8fADIzMwkKCgIT0/PEg0gL1kWZNmyZXrr+vTpQ58+fUo0BmMczzeTiJe9vOFaCCHMjdEDRQYPHmzKOMze8dsPdZZrVpKkJoQQ5qZITw5nZmayc+dO4uLiSElJ0RucoVAo+Pzzz0s0QHOx9y/dyZxH+VQuo0iEEEIYYnRSu379Oj169ODChQs4ODiQmppK1apVSU5ORq1W4+TkZPL7WmWloMcZmjrJyEchhDA3Rs/9OHPmTG7dusWPP/7IsWPH0Gg0REZGcuPGDd59911sbW3Zvn27KWMtM0mZ+o8LeFSW7kchhDA3Rie1X3/9leHDh9OyZUudmTusra2ZOHEiQUFBTJ8+3SRBlrX4AuZ8lNfNCCGE+TE6qd2/f5+6desCuQ9OA9y7d0+7vXXr1gU+mF0R5E9qdWXkoxBCmCWjk1rNmjW5ceMGAJUqVaJq1aqcPn1au/3q1atYWlbM+0xnk3WT2ovuMj2WEEKYI6MHirRu3Zo9e/Ywbdo0AHr06MHixYuxsLBArVbzxRdf0KlTJ5MFWpZy8g0UkYeuhRDCPBVplv7o6GgyMjKwsbFh1qxZXLlyhQ8//BDIfdfa3LlzTRZoWco/kXFde3mHmhBCmCOjr86+vr74+vpqlx0dHYmKiiIlJQWlUom9vb1JAjQH+/I9o+YmIx+FEMIsGX1PzRAHBwfs7e1JSkri/fffL4mYzJ6VdD8KIYRZMiqpaTQaEhMTyczM1Nt27do1pkyZgp+fH5988kmJB2gO7Cx0k1jdKtJSE0IIc1RoUtNoNMyZMwcPDw8aNWpErVq1ePXVV0lJSSE9PZ3p06cTEBDAqlWraNOmDd9++21pxV1qMnLgQbbuQJFadpLUhBDCHBV6T+2LL75g4cKFuLu7ExoayuXLl/n2229RqVQkJCRw7NgxBg0axOuvv079+vVLK+ZSdfuhbiutipUCC+l+FEIIs1RoUlu7di0BAQF89913WFvnvhBzxowZLF68mNq1a7N3714aN25cKoGWlfj7uo3ZBlVk5KMQQpirQrsfL1y4QN++fbUJDeC1114DYOLEiRU+oQGk55v2MUt/GkghhBBmotCklpGRgZOTk866atWqAeDl5WW6qMzI3Xzdj45W0vUohBDm6rGjHw1N3PvopMYV2ZFk3UEhLVysyigSIYQQj/PYG0QzZsxgwYIF2uWcnBwgd4YROzs7nbIKhYJDhw6VcIhl63K6blJXIC01IYQwV4UmtaCgoAJbajVq1DBZQOamvp2a6xn/tErvPZSbakIIYa4KTWrfffddacVhtrI0ukm9ibzxWgghzNbTcWPsCSRl6Sa1hg4ypF8IIcyVJLXHOJemW0UOVlJlQghhruQK/Rh2Kt0psmwtZKCIEEKYK0lqj/EgJ/9zalJlQghhruQKXQhNvjdeg7TUhBDCnElSK0RGjv46S5nMWAghzFaRh/Klp6dz4sQJbt26RXBwMNWrVzdFXGYhI0e/pSaEEMJ8Faml9sUXX+Dt7U23bt0ICwvjzJkzACQlJVGnTh1Wr15tkiDLSlq+B61r2ErDVgghzJnRV+l169Yxffp0XnjhBRYvXqxzv8nJyYl27dqxdetWkwRZVpKzdFtqdzJlNhEhhDBnRie1JUuW0KlTJyIjI+ncubPedn9/f86ePVuiwZW1G2m6N9XktTNCCGHejE5q58+fp1OnTga3Ozk5kZSUVOQAVq1ahZ+fH66uroSEhBAbG1toeY1Gw9KlS3n22WdxcXHB29ubWbNmFfm8xsg/JsRBXjsjhBBmzeiBIvb29qSkpBjcfv78+SIPGomKimLatGksXLiQVq1asWrVKvr168ehQ4dwd3cvcJ+3336bXbt28d577+Hr60tKSgo3b94s0nmNlZlvoIgMfBRCCPNmdEutTZs2rFu3jszMTL1t169f59///jcvvPBCkU6+ZMkSBg8ezJAhQ/D29mbBggW4uroSGRlZYPn4+HhWrFjB+vXr6dq1K56enjRt2pSOHTsW6bzGungvW2e5bU0bk5xHCCFEyTA6qb3zzjvcvn2btm3bsnLlShQKBT///DOzZs0iODgYS0tLpkyZYvSJs7KyiIuLIzQ0VGd9aGgohw8fLnCf77//Hk9PT3755ReaNm1KkyZNGDNmDLdu3TL6vEWhzjeiX4b4CyGEeTO6+9HLy4sff/yRadOmERERgUajYcmSJUBuK+7jjz+mdu3aRp84KSmJnJwcnJ2dddY7OzuTmJhY4D6XLl3i6tWrREVFsXTpUhQKBe+++y4DBw7k559/Nvg27vj4eKPj0tnvL0vgn1fN/C/pAfHxd4p1rIqkuPVZkUmd6JL60CX1oe9J6qRBgwYGtxXp4Wtvb2+2bt1KcnIyFy5cQK1W4+np+UQPYOd/CalGoynwxaQAarWazMxMli9fTv369QFYvnw5gYGBHD9+nMDAwAL3K6wCCmOblAzX07TLPbyq0KBBwff6nhbx8fHFrs+KSupEl9SHLqkPfaasE6O7Hy9duqT9t6OjI82bNycwMLDYCc3JyQmVSqXXKrt9+7Ze6y2Pq6srFhYW2oQGUK9ePSwsLLh27Vqx4iiMjUo3uV5/UMC8WUIIIcyG0UmtWbNmvPDCCyxdupQbN2488YmtrKzw9/cnOjpaZ310dDQtW7YscJ9WrVqRnZ3NxYsXtesuXbpEdna2wdGSTyIr3021ZtWtSvwcQgghSo7RSe29994jJyeHt99+myZNmtClSxciIyO5fft2sU8eHh7O+vXrWb16NWfPnmXq1KkkJCQQFhYGwOzZs+nRo4e2fNu2bWnatCnh4eGcPHmSkydPEh4eTmBgIM2aNSt2HIak5ptRxFpmyRJCCLNm9GV6woQJREdHc+LECaZPn05ycjKTJk3Cx8eH3r17s3bt2kKfYytI7969mTt3LgsWLOD555/n0KFDbNy4kTp16gCQkJCg0ypTKpV88803ODs707VrV/r06UPt2rVZv369wUEiT+L7K+k6y1YqeVBNCCHMmSI5ObnY49T/97//sXnzZrZt28aFCxewsrIiISGhJOMrUyP23mHzhX8S2+Sm9rzTvEoZRlT25Ka3PqkTXVIfuqQ+9JnFQJGCNGrUiB49etCtWzcqV65MVlZWScVlFrLzzfXYwKHIb+oRQghRiop1lT537hxbtmxh69at/Pnnn1haWtK+fXv69u1b0vGVqex8A0VspftRCCHMmtFJ7dKlS0RFRbFlyxb++OMPlEolbdq04fXXX6d79+44ODiYMs4y8TBfx6yFDBQRQgizZnRSa9asGQqFgpYtWzJ//nx69epVod96DfoTGlsYeChcCCGEeTA6qb333nv07t27SFNhlXe/3tCdvNlSWmpCCGHWjE5qEyZMMGUcZqlZdUtO3H6oXU7N3x8phBDCrBhMagcOHAAgODhYZ/lx8spXBPnHhbjYSlNNCCHMmcGk1q1bNxQKBQkJCVhZWWmXDcmbiPjOnYozi/3DfEP6888FKYQQwrwYTGo7d+4EcudofHT5afIw35B+C3n1tRBCmDWDSe25554rdPlp8Ptd3Tdfy0ARIYQwb0Zfprt3787evXsNbt+3bx/du3cvkaDMlYU01IQQwqwZndT2799v8I3UkPseNGMHk5QXNe10q0e6H4UQwryVWIfa9evXqVSpUkkdzixk5nsnaGVLSWpCCGHOCn1O7bvvvuP777/XLn/99df8+uuveuWSk5PZu3cvAQEBJR5gWbqTqTv80VpGPwohhFkrNKn98ccfbNmyBQCFQsHRo0c5duyYThmFQoGdnR2tWrVi3rx5pou0lKk1+g9ay5B+IYQwb4UmtcmTJzN58mQAqlatypIlS+jXr1+pBFbW8r92BsBS7qkJIYRZM3qarLt375oyDrOTIzNiCSFEuSNPXhmQk6/70U7G8wshhNkz2FLz8/NDqVRy9OhRLC0t8fPzK3SaLMi9vxYXF1fSMZaJ/C01uZ0mhBDmz2BSCw4ORqFQoFQqdZafFjn5psiSpCaEEObPYFJbtmxZocsVnX5LTbKaEEKYO7mnZoBeUpOaEkIIs2f0pfrAgQN88cUXOus2bdpEYGAg9evXZ+rUqajVBYyDL6fyz9Av3Y9CCGH+jE5qERERHD58WLt87tw5xo0bh1KppFmzZqxcuVIv6ZVnmfmaalbyjJoQQpg9o5Pa//73P51psDZu3IitrS2//PILmzZtYsCAAaxdu9YkQZaF/N2PVtJUE0IIs2d0UktNTcXR0VG7vHv3btq1a0eVKlUAaN26NVeuXCnxAMuKDOkXQojyx+ik5urqytmzZwH466+/OHXqFKGhodrtqampqFSqko+wjORPatL7KIQQ5s/oabK6d+/OypUryczM5Pjx41hbW9O5c2ft9t9++w1PT09TxFgm9J9Tk6wmhBDmzuikNn36dBITE9m4cSP29vZ8/vnnuLi4ALmttJ07dzJy5EiTBVra8k/9KN2PQghh/oxOapUqVWLFihUFbqtcuTK///47dnZ2JRZYWZPuRyGEKH+MTmr53bt3DwB7e3uUSiUODg4lFpQ5kGmyhBCi/CnSPBlXrlxh9OjReHl54eHhgYeHB15eXowZM6ZCjXwEyMjRXZZ7akIIYf6MTmrx8fG0bduWzZs306xZM8aMGcPo0aNp3rw5mzZtol27dvz5559FDmDVqlX4+fnh6upKSEgIsbGxRu13/vx53NzcqF27dpHPaYzkLN3ZUe49rDizpQghREVldPfj7Nmz0Wg0REdH4+fnp7Pt9OnT9OzZk9mzZ7NmzRqjTx4VFcW0adNYuHAhrVq1YtWqVfTr149Dhw7h7u5ucL+srCyGDRtGUFAQBw4cMPp8RWFvqdsyO3M32yTnEUIIUXKMbqnt37+f0aNH6yU0gCZNmjBy5EhiYmKKdPIlS5YwePBghgwZgre3NwsWLMDV1ZXIyMhC95s5cya+vr707NmzSOcrivwNsxdqW5vsXEIIIUqG0UktKytLO3tIQRwcHMjKyjL6xFlZWcTFxek8wA0QGhqqM8dkfrt27WLXrl1EREQYfa7iyM43UMRChj8KIYTZM7r7sXHjxnzzzTeEhYVha2ursy0zM5NvvvmGxo0bG33ipKQkcnJycHZ21lnv7OxMYmJigfskJCTwxhtvsGbNGuzt7Y0+V3x8vNFl81y7rQL+aZ1lPLhPfPydIh+nIipOfVZ0Uie6pD50SX3oe5I6adCggcFtRie1iRMn8sorr9CuXTuGDx+uPei5c+eIjIwkPj6+WBMa53+btkajMfiG7VGjRjFs2DCeffbZIp2jsAow5LTqAfzvrnbZ0d6eBg2qFfk4FU18fHyx6rMikzrRJfWhS+pDnynrxOik1qVLF1asWMHbb7/NlClTtIlHo9Hg6urKihUrdKbNehwnJydUKpVeq+z27dt6rbc8+/bt48CBA9quR41Gg1qtxsnJiYULFzJ06FCjz/84V+7rjum3kJeECiGE2SvSw9d9+/alV69exMXFaZ9Lq1OnDv7+/lhYFO05bisrK/z9/YmOjqZXr17a9dHR0fTo0aPAffIP9//+++9ZuHAhu3fvplatWkU6/+PkT2K30mVIvxBCmLvHZqLff/+dL7/8kkuXLlGtWjVeeuklunTpQmBg4BOfPDw8nNGjRxMQEEDLli2JjIwkISGBsLAwIPcxgmPHjrFjxw4AvXt2J06cQKlUFulenrHsLXWz2sV7MqRfCCHMXaFJ7dixY3Tv3p309HTtui1btrBw4UJt4nkSvXv35s6dOyxYsICbN2/i4+PDxo0bqVOnDpA7MOTixYtPfJ7iyDf4kXa1ZEi/EEKYu0LvFM2fPx8LCws2bNjA9evXiYmJ4ZlnnuHDDz8kO7tkWi4jRozg9OnTJCYmsnfvXoKDg7Xbli1bxunTpw3u+/LLL3P9+vUSiSO/HI28ekYIIcqbQpPa0aNHGTlyJC+++CJ2dnbahJaUlFTh5nrML39LTSY0FkII81doUktOTtYbdunt7Y1Go+Gvv/4yaWBlLf+rZ6ShJoQQ5q/QpKbRaFCpVDrr8pZLqvvRXOUf6ygtNSGEMH+PHf24a9cubty4oV1+8OABCoWCqKgo4uLidMoqFApef/31Eg+yLKjz9T8qpakmhBBm77FJbcuWLWzZskVv/erVq/XWVaSklr/7UVpqQghh/gpNaidPniytOMxO/u5Hmc9YCCHMX6FJLe95safRoZuZOsvSUhNCCPMnMxoa0MjRUmf54r0cAyWFEEKYC0lqBljna5rZSFNNCCHMniQ1A/JNKIKnvarggkIIIcyGJDUDNMiQfiGEKG8kqRmQf5osSWlCCGH+JKkZkC+nyZB+IYQoB4qU1K5cucLrr7+Ov78/7u7u7N+/H4CkpCQmTZqkN8NIeSYtNSGEKH+Mfl312bNnefHFF1Gr1QQGBnLlyhVycnKHuTs5OXH06FEyMzP5/PPPTRZsaZKWmhBClD9GJ7WZM2dib2/PL7/8gkqlon79+jrbO3bsyLZt20o6vjIjLTUhhCh/jO5+jI2NZcSIEbi4uKAoYCSgu7t7hXodTf7RjzL4UQghzJ/RSS07O5tKlSoZ3H737l2919SUZ3otNclqQghh9oxOao0bNyYmJqbAbRqNhp07d+Lv719ScZW5/A9fyzBRIYQwf0Zfq8eOHcv27duZP38+d+7cAUCtVnPu3DmGDRvGiRMnmDBhgskCLW35Z+mXhpoQQpg/oweK9OnTh6tXr/LBBx8wb9487TrIfRv2nDlz6NChg2miLAvSUhNCiHLH6KQG8Oabb9K3b1927NjBhQsXUKvV1K1blx49euDh4WGqGMuEtNSEEKL8KVJSA3Bzc2PcuHGmiMWs6N1Tk6QmhBBmT3rVDFDny2oKeVJNCCHMntEttapVqxo1rD1vEEl5F5f0UGdZWmpCCGH+jE5qU6ZM0UtqOTk5XL58mR9++IH69evTqVOnEg+wrFjly2Lp2fknzhJCCGFujE5q06dPN7jtxo0bvPDCCzRs2LBEgjIH9RwsOHIrS7ucmJ5ThtEIIYQwRoncU6tVqxZhYWHMnz+/JA5nFvLfU2voaFlGkQghhDBWiQ0UcXR05OLFiyV1uDKXf5osuacmhBDmr0SS2u3bt/n3v/9NnTp1SuJwZiF/UlNJUhNCCLNn9D217t27F7g+JSWFc+fO8fDhQyIjI0sssLKm11IrmzCEEEIUgdHXarVajUaj0fkB8PDwYPTo0Rw5coSePXsWOYBVq1bh5+eHq6srISEhxMbGGiwbExPDoEGD8Pb2pmbNmgQFBbFmzZoin9MY6nzzZCllShEhhDB7RrfUvvvuuxI/eVRUFNOmTWPhwoW0atWKVatW0a9fPw4dOoS7u7te+SNHjuDr68sbb7xBjRo12L17N2+++SY2Njb069evRGPTf/VMiR5eCCGECRjVUktPT6d79+6sXbu2RE++ZMkSBg8ezJAhQ/D29mbBggW4uroa7MacNGkS77zzDq1atcLT05Phw4fTvXt3duzYUaJxgQwUEUKI8siopGZra8vJkyfJySm5Z7WysrKIi4sjNDRUZ31oaCiHDx82+jj37t3D0dGxxOLKI/fUhBCi/DG6+/G5554jNjaWIUOGlMiJk5KSyMnJwdnZWWe9s7MziYmJRh3jxx9/ZO/evezatavQcvHx8UWO7959a+CfN3kn/PUX8VnyADYUrz4rOqkTXVIfuqQ+9D1JnTRo0MDgNqOTWkREBL179+bdd99l+PDh1KlTB6Xyydsv+afe0mg0Rs0xeejQIUaOHElERAQBAQGFli2sAgyxu3Qb7mZql91q16KBu02Rj1PRxMfHF6s+KzKpE11SH7qkPvSZsk4KTWobNmwgKCgIDw8Pnn32WTQaDUuWLGHJkiUolUosLXVn2VAoFNy4ccOoEzs5OaFSqfRaZbdv39ZrveV38OBB+vfvz/Tp0xk+fLhR5yuqew/zj340yWmEEEKUoEKTWnh4OMuXL8fDw4OXXnrJqBaUsaysrPD39yc6OppevXpp10dHR9OjRw+D+x04cIABAwYwdepUk77XLSVT9zWhktSEEML8FZrUNI/Mf7hs2bISP3l4eDijR48mICCAli1bEhkZSUJCAmFhYQDMnj2bY8eOaUc3xsTEMGDAAIYPH07//v25efMmACqViurVq5dobNVsdLtW72XJLP1CCGHuivzm65LUu3dv7ty5w4IFC7h58yY+Pj5s3LhRO91WQkKCznyS69ev58GDByxevJjFixdr17u7u3P69OkSjS1/Csuf5IQQQpifxya1kuxyLMiIESMYMWJEgdvytw6XLVtmkhZjQTT5H74ulbMKIYR4Eo9NauHh4UyYMMGogxVloIi5y99Sk3tqQghh/h6b1AICAvD09CyFUMyLtNSEEKL8eWxSCwsLK/F5FcuD/C01mftRCCHMn4x+MCB/S00qSgghzJ9cqw3I/+oZaakJIYT5k6RmgP49NclqQghh7gq9p3b37t3SisPsyD01IYQof6SlZoDekP4yiUIIIURRyLXaAHnztRBClD+S1AyQ59SEEKL8kaRmgNxTE0KI8keSmgHqfE01yWlCCGH+JKkZoN9Sk7QmhBDmTpKaIXJPTQghyp0yfZ+aOZNZ+su/7Oxs0tLSTH4eGxsbUlJSTH6e8kLqQ5fUhz5j6qRSpUpYWBQ9RUlSM0BvSH/ZhCGKKTs7m3v37uHo6GjyrmNra2tsbGxMeo7yROpDl9SHvsfViUajITk5GXt7+yInNul+NEBGP5ZvaWlppZLQhBAlT6FQ4OjoWKyeFklqBpxLydZZlooqfyShCVF+FffvV67VRsrJ33QTQghhdiSpGeBRWaWzbCk1JYQQZk8u1Qao8y1byPBH8ZS7fPkyjo6OnDhxolTO17VrV/71r39plx88eMBrr71GnTp1cHR05PLly3plStr+/fsJCAggJyfHZOd42ty6dYvGjRtz/fp1kxxfkpoBem++lpwmTEytVtO5c2cGDhyos/7BgwcEBgYyceJEnfX79+9n4MCB1KtXDxcXF5o2bcprr73G3r17tWViYmJwdHTU/tSsWZOgoCA2bNigd/5Tp04RFhZGw4YNcXV1pVmzZowdO5YzZ86Y5gM/xtq1a5kxY4bOcmxsLD/88ANnz57Fzc1Nr0xJmzFjBpMmTUKl0u25ycrKol69eri5uRU4NL1JkyYsXrxYb/3cuXNp3bq1zrrExESmTp2Kv78/Li4u+Pj40LdvX3766aeS/TD5XL16lQEDBlCrVi28vLyYMmUKWVlZhe6TmJjI2LFjadSoETVr1qRPnz6cP39ep8zNmzcZNWoUDRs2pFatWgQHB7Nx40btdmdnZ/r168fcuXNN8rkkqRkgExqL0qZUKlm2bBkxMTGsWbNGu37mzJlkZ2fz/vvva9d99dVX9OjRAwcHByIjIzly5AgrV67kueeeY+rUqXrHPnToEGfPnuXgwYP079+fcePGcfToUe32H3/8kRdeeIG0tDSWL1/O4cOHiYyMpEaNGsyePdu0H9yAqlWrYm9vr12+cOECDRs2xNfXF1dXV1QqlV6Z4nj48GGB6w8fPkx8fDy9evXS2/bdd9/h4eFBYGAgmzdvLva5L1++TEhICHv27GHmzJkcOHCAbdu20bFjR70vMSUpJyeHAQMGcP/+fb7//nu+/PJLduzYwdtvv21wH41Gw8svv8yFCxdYt24d+/btw93dnZ49e+qMUhwzZgznzp1j/fr1xMbGMnDgQEaPHs2BAwe0ZQYOHMimTZtM8s5OSWoGaPIN6lfKSDpRCjw9PXn//ff5v//7P65cucLevXuJjIxk2bJlVKpUCYBr164xdepUxowZw/LlywkJCcHT05MWLVowatQoDh48qHdcZ2dnXF1d8fT05M0336Rq1aqcOnUKyG0JhoeHExoaysaNG2nXrh2enp40a9aMmTNnsmLFigJjzcnJYfz48fj5+VGjRg2aN2/OokWLUKv/6bw/c+YMPXr0wN3dHTc3N4KDg9m3bx+Qm0ymTJlCo0aNcHFxwdfXl1mzZmn3fbRrsWvXrnzxxRfExsbi6OhI165d9cpAbgtq5syZNG7cmFq1atGuXTt2796t3Z7Xcv3pp58IDQ3F2dlZZ/ujNm/eTEhICHZ2dnrb1qxZw4ABAxg4cKDOF5Cimjx5MhqNhujoaF566SUaNGiAt7c3o0aNYv/+/cU+7uPs2bOHP/74g+XLl+Pv70+7du2YPXs2q1evJjU1tcB9zp8/z9GjR/noo48ICAigQYMGfPzxx2RkZLBlyxZtuSNHjjBixAgCAwPx9PRkwoQJ1K5dm+PHj2vL+Pj4UKNGDXbu3Fnin00evjZAHr6umBy/Mk0/viHJYbWLvM+wYcP49ttvGT16NFevXiU8PFyny2r79u1kZWXxxhtvFLh/YUOh1Wo133//PSkpKTRv3hyA3bt3k5SUxFtvvVXgPo6OjgaPVbNmTb7++mucnJw4fvw4b7zxBvb29gwbNgyAkSNH8swzz7B7924sLCw4c+aM9qHbL774gu+++44vv/ySOnXqcOPGDeLj4ws819q1a3nnnXeIj49nzZo1WFlZFVguPDycixcvsnLlSmrXrs1PP/3EwIED2bNnD02aNNGWmzVrFnPmzMHLy4vKlSsXeKzY2Fh69+6tt/7KlSvs37+fFStWYGtry6RJkzh16hR+fn4FHseQu3fv8ssvv/DOO+8UGIOhes+LrV+/foUef+LEiUyaNKnAbUeOHMHb2xs3Nzftuvbt25OZmUlcXBxt2rTR2yczMxNA56FppVKJtbU1Bw8e5LXXXgOgVatWbNu2jS5duuDo6MgPP/xAUlISISEhOscLCAhg//792v1KiiQ1A2SaLFGWPv74Y5o1a0bdunX1uoTOnz9PlSpVcHV11a778ccfGT58uHZ506ZNBAUFaZfzLriZmZloNBpmz55Ns2bNgNxuPQBvb+8ixWhpaakTm4eHBydPnmTr1q3apHb16lXGjx9Pw4YNAfDy8tKWv3r1KvXq1SMoKAiFQoG7uzstW7Ys8FxVq1bFzs4OS0tLnc/9qIsXL7J582ZOnTqFu7s7AKNGjeLXX3/l66+/ZuHChdqyU6dOJTQ0tNDPd/Xq1QLPtXbtWtq1a0f16tUB6NatG2vWrGHBggWFHi+/CxcuoNFotHVTFM2aNSMmJqbQMlWrVjW4LTExEWdnZ511Tk5OqFQqEhMTC9ynYcOGuLu789577/HZZ59RqVIlli5dyvXr17l586a23FdffcXw4cPx8vLCwsICa2trVq1apZf0a9SoYZJBR5LUDMjfUpOkJkrT2rVrsbW15caNG1y6dOmxCef5558nJiaG5ORkQkND9Ubr7dy5E0dHRzIzMzl27BhTp07F3t6eIUOGoMl/A7kIIiMjWb16NVevXiUjI4OHDx/qfPsfN24cr7/+Ohs2bCAkJIQePXpoL+KDBw/mpZdeIiAggNDQUDp06ECHDh1QKot3V+TkyZNoNBpatWqlsz4zM1Ov5ZGX0AuTkZGhN5WTWq1m/fr1vPfee9p1AwcOJCwsjPfff79I02E9Sb3b2trqfEEoDkMtekPrLS0tWbNmDePHj6du3bqoVCratm1Lhw4ddMrNmTOHpKQktm/fTrVq1fjuu+8YO3Ys3333nU5r2dbWlvT09Cf6DAWRe2oGSPejKCvHjx/n008/5d///jdt27Zl3LhxOkmqXr16pKamkpCQoF1XqVIlvLy88PDwKPCYHh4eeHl54ePjwyuvvEL//v2ZP3++9ngAZ8+eLVKcUVFRTJ8+ncGDB7NlyxZiYmIYPny4zgi66dOnc/jwYbp27cqRI0cIDg7W3oPy9/fn1KlTzJgxA7VazdixY+nVq5fOPbmiUKvVKBQK9uzZQ0xMjPbnyJEjfP755zpl8+5PFsbJyYnk5GSddXv27OHatWuMHDkSJycnnJyc6Nu3L8nJyezYsUNbzt7evsBRkSkpKVSpUgXIrXeFQsG5c+eK/FljY2OpXbt2oT+Ptkzzc3Fx0WuRJSUlkZOTo9eCe5S/vz/79+/n8uXLnD17li1btnDnzh3t/3cXL15kxYoVLFq0iJCQEJo0acK0adNo1qyZ3r3Zu3fvalu7JUlaagZI92PFVJx7XI9T0Df6JznWmDFjGDx4MB06dMDPz49WrVqxaNEi7Wi4nj17MmvWLD7++GNtYioqlUrFgwcPAAgNDcXJyYlPPvmE//znP3plk5OTC7y/c/DgQQICAhg1apR23cWLF/XK1atXj3r16jFmzBgmTpzImjVrePXVV4Hci3+vXr3o1asXgwcP5oUXXuDChQvUr1+/yJ/Jz88PjUbDzZs3C7wnVJzj5U/0a9asoXv37kyfPl1n/fLly1mzZg39+/cHoEGDBpw8eVLvmCdPntR+tqpVq9K+fXtWrlzJ6NGj9e6rGap3ePLuxxYtWvDRRx9x/fp1atfO/ZuIjo7G2toaf3//Qo8L4ODgAOR2hZ84cULbDZ33/1T+RyBUKpXel5U//vhDp4u8pEhSM0DefC3KwuzZs8nIyOCDDz4AwNXVlY8++oixY8fy4osv0rhxY9zc3Jg7dy7/+te/SE5O5uWXX8bT05Pk5GS2b98O6F9Ubt26RXZ2NpmZmRw/fpxvvvmGHj16ALmtls8++4yhQ4fSv39/xo4di5eXF3fv3uXbb7/l1KlTOs8Z5alfvz4bNmzg559/xsvLiy1bthAbG6ttiaSnp/Puu+/Ss2dP6tSpw61btzh06BABAQEAfP7559SoUYMmTZpgaWnJpk2bqFKlCrVq1SpW3dWvX1/7uMIHH3xA06ZNuXv3Lvv378fDw0P7eY0VGhqqM7IxKSmJH374ga+//prGjRvrlH311Vfp0KEDFy9epG7duowbN47OnTszf/58OnXqhJWVFZs3b+bo0aM6994++ugjOnXqRLt27Xj77bfx9fVFo9EQExPDJ598wm+//VZgbE/a/RgaGoqPjw9jxoxhzpw53L17lxkzZvDaa69pf383btygZ8+ezJgxg+7duwOwbds2qlWrRp06dThz5gzTpk2ja9eu2vuTDRs2xMvLi0mTJjFnzhyqVavGt99+S3R0NOvXr9ee/8GDB8TFxfHuu+8W+zMYIknNAP2WmqQ1YVoHDhxgxYoVbNu2TefZqz59+rBz507GjRvHL7/8goWFBSNGjKBhw4YsWbKEsLAwUlNTqVq1KoGBgWzYsEHvG3DefSYLCwtq167N0KFDmTZtmnZ7165d+fnnn/nkk08YNWoUKSkp1KpVi9atWxt8Ti0sLIzTp08zYsQINBoNPXr0IDw8XJsIVCoVycnJjB07lsTERKpVq0anTp20z9vZ29vz2WefceHCBRQKBU2aNGHTpk0FDqE31pIlS/joo4+YMWMGN27coGrVqjRv3pznn3++yMcaMGAAs2bN4o8//sDHx4cNGzZgbW1N+/bt9coGBgZSu3Zt1qxZw4wZM2jZsiWbN29mwYIFLF26FIVCQePGjdm+fTvPPPOMdj9PT0/27t3LwoULmTlzJn/99RfVqlXjmWee4ZNPPil2PTyOSqXim2++YfLkybz44ovY2NjQt29f5syZoy3z8OFD4uPjdYb4JyQk8Pbbb5OYmIirqysDBw5kypQp2u15X05mzZrFwIEDSUtLo27duixZsoTOnTtry+3atQs3NzeTtNQUycnJZTpV76pVq/jss8+4efMmjRo1Yu7cuYV+0DNnzvCvf/2L48ePU7VqVYYOHcqUKVNKfEb2OmtvkPrwn6q5/HJNHKzkFmR8fDwNGjQo6zAeKyUlRdtFYmol2f1YEVSk+pg1axa3b9/WuydXFBWpPkpK27ZtCQ8Pf+xjCcX5Oy7Tq3RUVBTTpk1j0qRJ7Nu3jxYtWtCvXz+uXr1aYPnU1FReeuklXFxc2LNnD/PmzWPx4sVP9D+cITJQRAgxceJEPD09Ze7HEnTr1i26detG3759TXL8Mm2ptW/fHl9fXz777DPtuubNm9OzZ09mzpypV/7LL79k1qxZnDt3DltbWwAWLFhAZGQkv//+e4m21mqvuUFa9j9Vc+2VmlSWqfqlpVYA+SauS+pDl9SHPmPrpFy11LKysoiLi9N7ADI0NJTDhw8XuM+RI0do3bq1NqFBbmL866+/uHz5conGJy01IYQof8psoIihZyKcnZ0NPtGemJioNzIqb//ExEQ8PT1LLL4X3W3IyNFw734adpXs5NUzQghRDpT56Mf8XYYajabQbsSCyhe0/lGG5pMrzP+5PbqUyZULJT+bdHlVnPosbTY2NlhbW5fa+TIyMkrtXOWB1IcuqQ99xtRJampqgY2cwm6BlFlSMzTP2O3btw0+0V7QU/C3b98GKPQp+Ce5B1Re7iGVlvJSHykpKaV2H0PumeiS+tAl9aHP2DqpUqWKdh5PY5XZPTUrKyv8/f2Jjo7WWR8dHW1wUtMWLVpw8OBBnQwfHR1NzZo1DU4PJJ5OFhYWpKWlPdH8ekKIsqHRaEhLS8PCoujtrjLtfgwPD2f06NEEBATQsmVLIiMjSUhIICwsDMidXeHYsWPaOdX69u1LREQE48aNY/Lkyfz55598+umnJnlOTZRvlSpVIjMz0+C7oUpSamqqdhYGIfWRn9SHPmPqpLi3EMo0qfXu3Zs7d+6wYMECbt68iY+PDxs3bqROnTpA7tPrj84l5+DgwNatW5k8eTLt2rXD0dGR8PBwxo8fX1YfQZgxa2vrUrmvlpiYWOQukopM6kOX1Ic+U9ZJmQ8UGTFiBCNGjChw27Jly/TW+fr68sMPP5g6LCGEEOWQPE0shBCiwpCkJoQQosKQpCaEEKLCKPNZ+oUQQoiSIi01IYQQFYYkNSGEEBWGJDUhhBAVhiQ1IYQQFYYkNSGEEBXGU5/UVq1ahZ+fH66uroSEhBAbG1to+TNnztClSxdq1KiBj48PERERFWrS3KLUR0xMDIMGDcLb25uaNWsSFBTEmjVrSjFa0yvq/x95zp8/j5ubG7Vr1zZxhKWvqHWi0WhYunQpzz77LC4uLnh7ezNr1qzSCbYUFLU+du/eTYcOHXBzc8PLy4tBgwbx559/llK0pnXgwAEGDhyIj48Pjo6OrFu37rH7lPQ19alOalFRUUybNo1Jkyaxb98+WrRoQb9+/bh69WqB5VNTU3nppZdwcXFhz549zJs3j8WLF/P555+XcuSmUdT6OHLkCL6+vvz73//m4MGDDB8+nDfffJNNmzaVcuSmUdT6yJOVlcWwYcMICgoqpUhLT3Hq5O233+bLL79k1qxZHDlyhI0bN1aYuilqfVy6dInBgwfTunVr9u3bx7Zt28jIyKBfv36lHLlppKWl0bhxY+bNm4etre1jy5vimvpUP6fWvn17fH19+eyzz7TrmjdvTs+ePZk5c6Ze+bw/zHPnzml/YQsWLCAyMpLff/+93L8poKj1UZChQ4eSk5NTIVpsxa2P6dOnk5KSQnBwMFOmTOH69eulEW6pKGqdxMfH07p1aw4cOIC3t3dphloqilof27dvJywsjFu3bqFSqQDYt28fPXr04Pz58zg5OZVa7KZWu3Zt5s+fz8svv2ywjCmuqU9tSy0rK4u4uDhCQ0N11oeGhnL48OEC9zly5AitW7fW+QbSvn17/vrrLy5fvmzSeE2tOPVRkHv37uHo6FjC0ZW+4tbHrl272LVrFxEREaYOsdQVp06+//57PD09+eWXX2jatClNmjRhzJgx3Lp1qzRCNqni1Ie/vz+WlpasXr2anJwc7t27x4YNG2jevHmFSmjGMsU19alNaklJSeTk5Oi9MdvZ2bnA14dD7usSCiqft608K0595Pfjjz+yd+9ehg4daoIIS1dx6iMhIYE33niD5cuXY29vXxphlqri1MmlS5e4evUqUVFRLF26lOXLlxMfH8/AgQNRq9WlEbbJFKc+PDw82Lp1K3PnzsXFxYU6derw+++/880335RGyGbHFNfUpzap5cnfvNVoNIU2eQsqX9D68qqo9ZHn0KFDjBw5koiICAICAkwVXqkrSn2MGjWKYcOG8eyzz5ZGaGWmKHWiVqvJzMxk+fLlBAcHExQUxPLlyzl27BjHjx8vjXBNrij1cfPmTSZMmMDAgQPZs2cP3377LZUrV2bo0KHlPskXV0lfU5/apObk5IRKpdL7NnD79m29bw55XFxcCiwPGNynvChOfeQ5ePAg/fr1Y/r06QwfPtyUYZaa4tTHvn37iIiIwMnJCScnJyZMmEBaWhpOTk58/fXXpRC1aRWnTlxdXbGwsKB+/fradfXq1cPCwoJr166ZNF5TK059rFy5Ejs7O9577z2aNm1KcHAwK1as4MCBA0Xq5q8oTHFNfWqTmpWVFf7+/kRHR+usj46OpmXLlgXu06JFCw4ePEhGRoZO+Zo1a+Lh4WHSeE2tOPUBuUN4+/Xrx5QpUxg3bpypwyw1xamP2NhYYmJitD//93//h62tLTExMfTq1asUojat4tRJq1atyM7O1nmD/aVLl8jOzi73b4MuTn2kp6drB4jkyVt+GltqprimPrVJDSA8PJz169ezevVqzp49y9SpU0lISCAsLAyA2bNn06NHD235vn37Ymtry7hx4/j999/ZsWMHn376KePGjasQ3Y9FrY+YmBj69etHWFgY/fv35+bNm9y8eVP7Tau8K2p9NG7cWOenZs2aKJVKGjduXCEGz0DR66Rt27Y0bdqU8PBwTp48ycmTJwkPDycwMJBmzZqV1ccoMUWtj44dO3Ly5EnmzZvH+fPniYuLIzw8HDc3N/z9/cvoU5Sc+/fvc+rUKU6dOoVarebatWucOnVK+4hDaVxTLUrkk5RTvXv35s6dOyxYsICbN2/i4+PDxo0bqVOnDpB74//Rb5gODg5s3bqVyZMn065dOxwdHQkPD2f8+PFl9RFKVFHrY/369Tx48IDFixezePFi7Xp3d3dOnz5d6vGXtKLWx9OgqHWiVCr55ptvmDp1Kl27dsXGxoZ27drxwQcfoFSW/+/URa2PkJAQVq1axaJFi1i8eDE2NjYEBgayefNmKlWqVFYfo8ScOHGC7t27a5fnzp3L3LlzGTRoEMuWLSuVa+pT/ZyaEEKIiqX8f1USQggh/iZJTQghRIUhSU0IIUSFIUlNCCFEhSFJTQghRIUhSU0IIUSFIUlNVHiOjo7MnTu3rMMwqZiYGBwdHYmJiTGqfJMmTRg7dqyJoxKi9ElSE2Zp3bp1ODo6Fvjz1ltvlXV4j9W1a1edmGvUqEFwcDDLly8vtemQfvzxR7NL5vl/r05OTvj4+DB27Fhu3LhR7OMuWLCAb7/9tgQjFeXVUz2jiDB/06ZNo27dujrrHp0c15zVqFGD2bNnA7mTtObNrJGYmMi7775boucKDg4mISEBKysr7bpdu3bx1VdfMX36dL3y//3vf8t0Ro+832tmZiZHjx5l/fr1HDx4kIMHDxr1xuT8PvroI3r37k23bt1MEK0oTySpCbPWvn37cvsqF3t7ewYMGKBdDgsL49lnn+WLL75g+vTpWFiU3J+fUqnExsbG6PLW1tYldu7iePT3+tprr1GtWjUWLVrEjz/+yEsvvVSmsYnyTbofRbl09+5d3nnnHYKCgnBzc6N27dp069aNQ4cOPXbf7OxsFixYQEBAADVq1MDLy4uOHTuyfft2nXLnz59n2LBh1KtXDxcXF4KCgli7dm2xY7azsyMwMJC0tDTtm5+vXr3KyJEj8fLywtXVleeee44NGzbo7bt161batWuHu7s7derUISgoSOft2vnvqY0dO5avvvoKQKe7L+9two/eU0tMTMTJyYk5c+bonbegbVlZWcyfP5/AwEBcXFxo2LAhb731FsnJycWum6CgIACdeQGzsrL44IMPaNu2LR4eHtSoUYP27dvz/fff6+zr6OhIZmYmGzZs0H7Orl27arenpqbyzjvv0KRJE1xcXHjmmWeYNWsWmZmZxY5XmC9pqQmzlpqaSlJSks66atWqcenSJbZv307Pnj3x8vIiJSWF1atX07NnT6Kjo2ncuLHBY86bN4+FCxfy6quvEhAQQFpaGqdOneK///0vPXv2BODs2bN06tQJJycnwsPDcXBw4KeffmL8+PGkpqYW+zU7ly5dQqVS4eDgQFJSEi+++CJ3795l1KhR1KhRg6ioKMaOHUtycrI26fz6668MGzaMNm3aMGPGDFQqFfHx8cTGxho8T1hYGNevX2ffvn0sX75cu7569ep6ZV1cXHjuuefYunUr77zzjs62bdu2kZOTQ58+fYDcFzi+8sor7Nu3j1dffRVfX18uXrzIypUriYuL46effsLS0rLI9XLlyhUAqlatql137949vvrqK1566SVeeeUV0tPT2bRpEy+//DKbN2+mffv2ACxfvpzx48cTGBiofeu6i4sLkPuql27dunH58mWGDh1K3bp1OX36NJ9//jnnzp1j/fr1RY5VmDdJasKs5V1MH3X+/HkaN25MXFyczruphg4dqu3e++yzzwwec9euXXTs2LHQMtOmTcPV1ZXo6Gjs7OwAGD58OGFhYcydO5chQ4Y8dlb1nJwcbUJOSkoiMjKSkydP0rlzZ+zs7Pjwww+5fv0627dvJyQkBIBhw4bRuXNn5syZw+DBg3FwcGDXrl3Y29sTFRWl9y4uQ1q0aEG9evXYt2+fTheoIX369OH1118nLi5O5xUoUVFRNG7cGB8fHwA2b97Mzz//zPbt22nTpo22XHBwMP3792fLli0MHDjwsefL+7KSkZHBf//7XyIiIrC1teXFF1/UlnF0dOTMmTM6XaWjR4/m+eefZ/HixdqkNmDAAF5//XU8PT31PuvSpUuJj4/n119/xdvbW7vex8eHyZMnExsbq20liopBuh+FWYuIiGDbtm06P1WqVMHa2lp7gc/IyODOnTuo1WoCAgKIi4sr9Jj29vb88ccf/PnnnwVuT05O5tdff6VXr16kp6eTlJSk/XnhhRe4d+8eJ06ceGzsFy5coF69etSrV48WLVqwYsUK+vfvz5IlS4Dc5Orn56dNaJD74smxY8eSlpbG/v37tfGmpaWxZ88eY6qsWHr06IGVlRVRUVHaddevX+fw4cP07t1bu27r1q3Ur18fX19fnXoJCAigcuXK7Nu3z6jz9enTh3r16uHr68uQIUOwt7fnP//5DzVr1tSWUalU2oSWlZXF3bt3uXfvHsHBwY/9HT8ab8uWLalevbpOvG3btgUwOl5RfkhLTZi15s2bFzhQRK1Ws2jRIr7++mvtfaI8j3tj7vTp03nllVcIDAykUaNGhIaG0rdvX5o3bw7ktgQ1Gg0RERE6960eZcyLUN3c3Pj8889RKBQ4ODjg6emp87LQK1eu6Lx7Kk9eiyKvS2748OFs27aNfv36UbNmTUJCQujevTtdunQpsZfTOjo60q5dO6Kiopg9ezYKhYKoqCg0Go1Oa/n8+fPEx8dTr169Ao9j7AtiIyIi8Pb2JiUlhbVr13Lw4MECW6GrV69m6dKlnD17Fo3mn7dkGfu5z58/z2+//fbE8YryQ5KaKJc+/fRT3nvvPQYNGsQ777xDtWrVUKlUfPzxx499cefzzz/PyZMn+eGHH4iOjuY///kPy5Yt491332XixIna58jGjRtHx44dCzxGYffs8tja2mpbBEXx6MUbwNXVlf379xMdHc0vv/zC7t27+c9//kOHDh3YuHFjiSW2vn37smvXLo4cOULLli2JioqiWbNmOo9UqNVqGjVqxLx58wo8RrVq1Yw616NfVrp160aXLl0YOXIkR48epXLlykBuV+frr79O586deeONN3B2dsbCwoJ169axadMmo86jVqtp06YNEydOLHB7rVq1jDqOKD8kqYlyKSoqiueee45ly5bprDf2YWNHR0cGDRrEoEGDSE9Pp2/fvkRERPDGG2/g6ekJgIWFRbGSkrHq1KnDuXPn9NbHx8drt+exsrKiU6dOdOrUCY1Gw+zZs/n00085fPgwrVq1KvD4RU12Xbp0wc7Oji1btuDi4sKJEyd4//33dcrUrVuXuLg42rRpU2LPualUKmbNmkXnzp1Zvnw5kyZNAnJ/x56enqxfv17ns6xbt07vGIY+a926dbl//75Jf4/CvMg9NVEuqVQqvRbN4cOHOXLkyGP3vXPnjs6yra0t3t7eZGZm8uDBA5ydnWnTpg1ff/01165d09u/pLqsOnXqxKlTp3Tu6zx8+JAvvvgCOzs7nnvuuQLjVSgU+Pn5ARQ6jD5vgIuxQ+0rVapEp06d2L59O5s2bUKhUOg9M9a7d28SExNZsWKF3v7Z2dnFHtbfunVrWrRowbJly0hPTwfQdkc++nu+dOlSgTOH2NnZFXju3r17c/z4cb3HACB3ZOT9+/eLFa8wX9JSE+VS586dmTdvHqNHjyYoKIjz58/z9ddf06hRo8deqFq0aEFQUBDNmzenWrVq/Pbbb6xevZpOnTphb28PwMcff0ynTp0IDg5myJAh1KtXj6SkJE6ePMmePXu4evXqE3+Gt956i6ioKAYNGsTo0aNxdXVl69atHD16lA8//BAHBwcAJkyYwJ07d2jTpg21a9fmr7/+YuXKldqptwxp1qwZAP/617944YUXsLCw4MUXXyx01Gbv3r3ZunUrixcvplWrVri5uels79+/Pzt37mTatGkcOHCA4OBgFAoFFy5cYMeOHcyZM6fAEavGGD9+PK+99hqrV69m9OjRdO7cmZ07dzJo0CA6d+7MjRs3+PLLL6lXrx6//fab3mfdu3cvixcvplatWlSvXp2QkBAmTJjATz/9xKuvvkr//v0JCAggMzOTP//8k61bt7Jp06Zy+3C/KJgkNVEuTZw4Ufvc0vbt2/Hx8SEyMpItW7ZoRw0aMnbsWH744Qf27dtHRkYGtWvX5s033+TNN9/Ulqlfvz6//vor8+fPZ9OmTdy+fRsnJye8vb31uuSKy8nJiV27djF79my++uorHjx4QP369Vm2bBmDBg3Sluvfvz+rV6/mq6++Ijk5GRcXFzp06MDUqVO1SbggvXr14siRI2zdupXNmzej0Wg4efJkoUmtY8eOVKlShdTUVJ1Rj3mUSiWrV69m+fLlrF+/np9//hkrKyvc3d3p378/rVu3LnZ9dOvWDS8vLxYvXsywYcMYPHgwt2/f5ssvv+TXX3/Fy8uLDz/8kAsXLugltXnz5jFx4kTmzZtHWloawcHBhISEYGtry44dO1i0aBFRUVFs2bKFSpUq4enpydixY2nQoEGx4xXmSZGcnKx5fDEhhBDC/Mk9NSGEEBWGJDUhhBAVhiQ1IYQQFYYkNSGEEBWGJDUhhBAVhiQ1IYQQFYYkNSGEEBWGJDUhhBAVhiQ1IYQQFYYkNSGEEBXG/wPnm9zLndPW2wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(xgb_c, X_test, Y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158392, 68)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd_X_train = pd.DataFrame(X_train)\n",
    "importances = list(xgb_c.feature_importances_)\n",
    "feature_list = pd_X_train.columns.values.tolist()\n",
    "\n",
    "%matplotlib inline\n",
    "# Set the style\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, importances, orientation = 'vertical')\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, feature_list, rotation='vertical')\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall / Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>F1</th>\n",
       "      <th>FN_Cost</th>\n",
       "      <th>FP_Cost</th>\n",
       "      <th>Tot_Cost</th>\n",
       "      <th>Cost_per_Obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>19026</td>\n",
       "      <td>0</td>\n",
       "      <td>28492</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400396</td>\n",
       "      <td>0.400396</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571832</td>\n",
       "      <td>0</td>\n",
       "      <td>284920</td>\n",
       "      <td>284920</td>\n",
       "      <td>5.996044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>18929</td>\n",
       "      <td>15823</td>\n",
       "      <td>12669</td>\n",
       "      <td>97</td>\n",
       "      <td>0.731344</td>\n",
       "      <td>0.599057</td>\n",
       "      <td>0.994902</td>\n",
       "      <td>0.455312</td>\n",
       "      <td>0.747827</td>\n",
       "      <td>48500</td>\n",
       "      <td>126690</td>\n",
       "      <td>175190</td>\n",
       "      <td>3.686813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.04</td>\n",
       "      <td>18859</td>\n",
       "      <td>19299</td>\n",
       "      <td>9193</td>\n",
       "      <td>167</td>\n",
       "      <td>0.803022</td>\n",
       "      <td>0.672287</td>\n",
       "      <td>0.991223</td>\n",
       "      <td>0.505766</td>\n",
       "      <td>0.801181</td>\n",
       "      <td>83500</td>\n",
       "      <td>91930</td>\n",
       "      <td>175430</td>\n",
       "      <td>3.691864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.06</td>\n",
       "      <td>18781</td>\n",
       "      <td>21021</td>\n",
       "      <td>7471</td>\n",
       "      <td>245</td>\n",
       "      <td>0.837619</td>\n",
       "      <td>0.715412</td>\n",
       "      <td>0.987123</td>\n",
       "      <td>0.528139</td>\n",
       "      <td>0.829586</td>\n",
       "      <td>122500</td>\n",
       "      <td>74710</td>\n",
       "      <td>197210</td>\n",
       "      <td>4.150217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.08</td>\n",
       "      <td>18733</td>\n",
       "      <td>22101</td>\n",
       "      <td>6391</td>\n",
       "      <td>293</td>\n",
       "      <td>0.859338</td>\n",
       "      <td>0.745622</td>\n",
       "      <td>0.984600</td>\n",
       "      <td>0.541240</td>\n",
       "      <td>0.848607</td>\n",
       "      <td>146500</td>\n",
       "      <td>63910</td>\n",
       "      <td>210410</td>\n",
       "      <td>4.428006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.10</td>\n",
       "      <td>18667</td>\n",
       "      <td>22887</td>\n",
       "      <td>5605</td>\n",
       "      <td>359</td>\n",
       "      <td>0.874490</td>\n",
       "      <td>0.769075</td>\n",
       "      <td>0.981131</td>\n",
       "      <td>0.550777</td>\n",
       "      <td>0.862257</td>\n",
       "      <td>179500</td>\n",
       "      <td>56050</td>\n",
       "      <td>235550</td>\n",
       "      <td>4.957069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.12</td>\n",
       "      <td>18610</td>\n",
       "      <td>23495</td>\n",
       "      <td>4997</td>\n",
       "      <td>416</td>\n",
       "      <td>0.886085</td>\n",
       "      <td>0.788325</td>\n",
       "      <td>0.978135</td>\n",
       "      <td>0.558010</td>\n",
       "      <td>0.873033</td>\n",
       "      <td>208000</td>\n",
       "      <td>49970</td>\n",
       "      <td>257970</td>\n",
       "      <td>5.428890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.14</td>\n",
       "      <td>18549</td>\n",
       "      <td>24022</td>\n",
       "      <td>4470</td>\n",
       "      <td>477</td>\n",
       "      <td>0.895892</td>\n",
       "      <td>0.805813</td>\n",
       "      <td>0.974929</td>\n",
       "      <td>0.564281</td>\n",
       "      <td>0.882340</td>\n",
       "      <td>238500</td>\n",
       "      <td>44700</td>\n",
       "      <td>283200</td>\n",
       "      <td>5.959847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.16</td>\n",
       "      <td>18484</td>\n",
       "      <td>24398</td>\n",
       "      <td>4094</td>\n",
       "      <td>542</td>\n",
       "      <td>0.902437</td>\n",
       "      <td>0.818673</td>\n",
       "      <td>0.971513</td>\n",
       "      <td>0.568957</td>\n",
       "      <td>0.888568</td>\n",
       "      <td>271000</td>\n",
       "      <td>40940</td>\n",
       "      <td>311940</td>\n",
       "      <td>6.564670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.18</td>\n",
       "      <td>18408</td>\n",
       "      <td>24739</td>\n",
       "      <td>3753</td>\n",
       "      <td>618</td>\n",
       "      <td>0.908014</td>\n",
       "      <td>0.830648</td>\n",
       "      <td>0.967518</td>\n",
       "      <td>0.573365</td>\n",
       "      <td>0.893874</td>\n",
       "      <td>309000</td>\n",
       "      <td>37530</td>\n",
       "      <td>346530</td>\n",
       "      <td>7.292605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.20</td>\n",
       "      <td>18341</td>\n",
       "      <td>25019</td>\n",
       "      <td>3473</td>\n",
       "      <td>685</td>\n",
       "      <td>0.912496</td>\n",
       "      <td>0.840790</td>\n",
       "      <td>0.963997</td>\n",
       "      <td>0.577006</td>\n",
       "      <td>0.898188</td>\n",
       "      <td>342500</td>\n",
       "      <td>34730</td>\n",
       "      <td>377230</td>\n",
       "      <td>7.938676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.22</td>\n",
       "      <td>18280</td>\n",
       "      <td>25278</td>\n",
       "      <td>3214</td>\n",
       "      <td>746</td>\n",
       "      <td>0.916663</td>\n",
       "      <td>0.850470</td>\n",
       "      <td>0.960790</td>\n",
       "      <td>0.580330</td>\n",
       "      <td>0.902270</td>\n",
       "      <td>373000</td>\n",
       "      <td>32140</td>\n",
       "      <td>405140</td>\n",
       "      <td>8.526032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.24</td>\n",
       "      <td>18209</td>\n",
       "      <td>25468</td>\n",
       "      <td>3024</td>\n",
       "      <td>817</td>\n",
       "      <td>0.919167</td>\n",
       "      <td>0.857580</td>\n",
       "      <td>0.957059</td>\n",
       "      <td>0.583099</td>\n",
       "      <td>0.904593</td>\n",
       "      <td>408500</td>\n",
       "      <td>30240</td>\n",
       "      <td>438740</td>\n",
       "      <td>9.233133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.26</td>\n",
       "      <td>18136</td>\n",
       "      <td>25674</td>\n",
       "      <td>2818</td>\n",
       "      <td>890</td>\n",
       "      <td>0.921966</td>\n",
       "      <td>0.865515</td>\n",
       "      <td>0.953222</td>\n",
       "      <td>0.586031</td>\n",
       "      <td>0.907254</td>\n",
       "      <td>445000</td>\n",
       "      <td>28180</td>\n",
       "      <td>473180</td>\n",
       "      <td>9.957911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.28</td>\n",
       "      <td>18068</td>\n",
       "      <td>25852</td>\n",
       "      <td>2640</td>\n",
       "      <td>958</td>\n",
       "      <td>0.924281</td>\n",
       "      <td>0.872513</td>\n",
       "      <td>0.949648</td>\n",
       "      <td>0.588616</td>\n",
       "      <td>0.909448</td>\n",
       "      <td>479000</td>\n",
       "      <td>26400</td>\n",
       "      <td>505400</td>\n",
       "      <td>10.635970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.30</td>\n",
       "      <td>18002</td>\n",
       "      <td>26011</td>\n",
       "      <td>2481</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.926238</td>\n",
       "      <td>0.878875</td>\n",
       "      <td>0.946179</td>\n",
       "      <td>0.590984</td>\n",
       "      <td>0.911286</td>\n",
       "      <td>512000</td>\n",
       "      <td>24810</td>\n",
       "      <td>536810</td>\n",
       "      <td>11.296982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.32</td>\n",
       "      <td>17932</td>\n",
       "      <td>26166</td>\n",
       "      <td>2326</td>\n",
       "      <td>1094</td>\n",
       "      <td>0.928027</td>\n",
       "      <td>0.885181</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>0.593360</td>\n",
       "      <td>0.912942</td>\n",
       "      <td>547000</td>\n",
       "      <td>23260</td>\n",
       "      <td>570260</td>\n",
       "      <td>12.000926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.34</td>\n",
       "      <td>17874</td>\n",
       "      <td>26311</td>\n",
       "      <td>2181</td>\n",
       "      <td>1152</td>\n",
       "      <td>0.929858</td>\n",
       "      <td>0.891249</td>\n",
       "      <td>0.939451</td>\n",
       "      <td>0.595474</td>\n",
       "      <td>0.914716</td>\n",
       "      <td>576000</td>\n",
       "      <td>21810</td>\n",
       "      <td>597810</td>\n",
       "      <td>12.580706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.36</td>\n",
       "      <td>17818</td>\n",
       "      <td>26443</td>\n",
       "      <td>2049</td>\n",
       "      <td>1208</td>\n",
       "      <td>0.931458</td>\n",
       "      <td>0.896864</td>\n",
       "      <td>0.936508</td>\n",
       "      <td>0.597433</td>\n",
       "      <td>0.916257</td>\n",
       "      <td>604000</td>\n",
       "      <td>20490</td>\n",
       "      <td>624490</td>\n",
       "      <td>13.142178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.38</td>\n",
       "      <td>17738</td>\n",
       "      <td>26584</td>\n",
       "      <td>1908</td>\n",
       "      <td>1288</td>\n",
       "      <td>0.932741</td>\n",
       "      <td>0.902881</td>\n",
       "      <td>0.932303</td>\n",
       "      <td>0.599792</td>\n",
       "      <td>0.917356</td>\n",
       "      <td>644000</td>\n",
       "      <td>19080</td>\n",
       "      <td>663080</td>\n",
       "      <td>13.954291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.40</td>\n",
       "      <td>17664</td>\n",
       "      <td>26690</td>\n",
       "      <td>1802</td>\n",
       "      <td>1362</td>\n",
       "      <td>0.933415</td>\n",
       "      <td>0.907428</td>\n",
       "      <td>0.928414</td>\n",
       "      <td>0.601750</td>\n",
       "      <td>0.917801</td>\n",
       "      <td>681000</td>\n",
       "      <td>18020</td>\n",
       "      <td>699020</td>\n",
       "      <td>14.710636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.42</td>\n",
       "      <td>17571</td>\n",
       "      <td>26799</td>\n",
       "      <td>1693</td>\n",
       "      <td>1455</td>\n",
       "      <td>0.933751</td>\n",
       "      <td>0.912116</td>\n",
       "      <td>0.923526</td>\n",
       "      <td>0.603989</td>\n",
       "      <td>0.917785</td>\n",
       "      <td>727500</td>\n",
       "      <td>16930</td>\n",
       "      <td>744430</td>\n",
       "      <td>15.666274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.44</td>\n",
       "      <td>17490</td>\n",
       "      <td>26898</td>\n",
       "      <td>1594</td>\n",
       "      <td>1536</td>\n",
       "      <td>0.934130</td>\n",
       "      <td>0.916475</td>\n",
       "      <td>0.919268</td>\n",
       "      <td>0.605975</td>\n",
       "      <td>0.917869</td>\n",
       "      <td>768000</td>\n",
       "      <td>15940</td>\n",
       "      <td>783940</td>\n",
       "      <td>16.497748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.46</td>\n",
       "      <td>17422</td>\n",
       "      <td>26975</td>\n",
       "      <td>1517</td>\n",
       "      <td>1604</td>\n",
       "      <td>0.934320</td>\n",
       "      <td>0.919901</td>\n",
       "      <td>0.915694</td>\n",
       "      <td>0.607586</td>\n",
       "      <td>0.917793</td>\n",
       "      <td>802000</td>\n",
       "      <td>15170</td>\n",
       "      <td>817170</td>\n",
       "      <td>17.197062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.48</td>\n",
       "      <td>17337</td>\n",
       "      <td>27052</td>\n",
       "      <td>1440</td>\n",
       "      <td>1689</td>\n",
       "      <td>0.934151</td>\n",
       "      <td>0.923310</td>\n",
       "      <td>0.911227</td>\n",
       "      <td>0.609430</td>\n",
       "      <td>0.917229</td>\n",
       "      <td>844500</td>\n",
       "      <td>14400</td>\n",
       "      <td>858900</td>\n",
       "      <td>18.075256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.50</td>\n",
       "      <td>17256</td>\n",
       "      <td>27124</td>\n",
       "      <td>1368</td>\n",
       "      <td>1770</td>\n",
       "      <td>0.933962</td>\n",
       "      <td>0.926546</td>\n",
       "      <td>0.906969</td>\n",
       "      <td>0.611176</td>\n",
       "      <td>0.916653</td>\n",
       "      <td>885000</td>\n",
       "      <td>13680</td>\n",
       "      <td>898680</td>\n",
       "      <td>18.912412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.52</td>\n",
       "      <td>17182</td>\n",
       "      <td>27199</td>\n",
       "      <td>1293</td>\n",
       "      <td>1844</td>\n",
       "      <td>0.933983</td>\n",
       "      <td>0.930014</td>\n",
       "      <td>0.903080</td>\n",
       "      <td>0.612852</td>\n",
       "      <td>0.916349</td>\n",
       "      <td>922000</td>\n",
       "      <td>12930</td>\n",
       "      <td>934930</td>\n",
       "      <td>19.675281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.54</td>\n",
       "      <td>17086</td>\n",
       "      <td>27276</td>\n",
       "      <td>1216</td>\n",
       "      <td>1940</td>\n",
       "      <td>0.933583</td>\n",
       "      <td>0.933559</td>\n",
       "      <td>0.898034</td>\n",
       "      <td>0.614851</td>\n",
       "      <td>0.915452</td>\n",
       "      <td>970000</td>\n",
       "      <td>12160</td>\n",
       "      <td>982160</td>\n",
       "      <td>20.669220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.56</td>\n",
       "      <td>16982</td>\n",
       "      <td>27345</td>\n",
       "      <td>1147</td>\n",
       "      <td>2044</td>\n",
       "      <td>0.932847</td>\n",
       "      <td>0.936731</td>\n",
       "      <td>0.892568</td>\n",
       "      <td>0.616893</td>\n",
       "      <td>0.914117</td>\n",
       "      <td>1022000</td>\n",
       "      <td>11470</td>\n",
       "      <td>1033470</td>\n",
       "      <td>21.749021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.58</td>\n",
       "      <td>16859</td>\n",
       "      <td>27426</td>\n",
       "      <td>1066</td>\n",
       "      <td>2167</td>\n",
       "      <td>0.931963</td>\n",
       "      <td>0.940530</td>\n",
       "      <td>0.886103</td>\n",
       "      <td>0.619307</td>\n",
       "      <td>0.912506</td>\n",
       "      <td>1083500</td>\n",
       "      <td>10660</td>\n",
       "      <td>1094160</td>\n",
       "      <td>23.026222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.60</td>\n",
       "      <td>16746</td>\n",
       "      <td>27496</td>\n",
       "      <td>996</td>\n",
       "      <td>2280</td>\n",
       "      <td>0.931058</td>\n",
       "      <td>0.943862</td>\n",
       "      <td>0.880164</td>\n",
       "      <td>0.621491</td>\n",
       "      <td>0.910901</td>\n",
       "      <td>1140000</td>\n",
       "      <td>9960</td>\n",
       "      <td>1149960</td>\n",
       "      <td>24.200513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.62</td>\n",
       "      <td>16626</td>\n",
       "      <td>27554</td>\n",
       "      <td>938</td>\n",
       "      <td>2400</td>\n",
       "      <td>0.929753</td>\n",
       "      <td>0.946595</td>\n",
       "      <td>0.873857</td>\n",
       "      <td>0.623676</td>\n",
       "      <td>0.908773</td>\n",
       "      <td>1200000</td>\n",
       "      <td>9380</td>\n",
       "      <td>1209380</td>\n",
       "      <td>25.450987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.64</td>\n",
       "      <td>16477</td>\n",
       "      <td>27612</td>\n",
       "      <td>880</td>\n",
       "      <td>2549</td>\n",
       "      <td>0.927838</td>\n",
       "      <td>0.949300</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.626279</td>\n",
       "      <td>0.905753</td>\n",
       "      <td>1274500</td>\n",
       "      <td>8800</td>\n",
       "      <td>1283300</td>\n",
       "      <td>27.006608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.66</td>\n",
       "      <td>16358</td>\n",
       "      <td>27672</td>\n",
       "      <td>820</td>\n",
       "      <td>2668</td>\n",
       "      <td>0.926596</td>\n",
       "      <td>0.952265</td>\n",
       "      <td>0.859771</td>\n",
       "      <td>0.628481</td>\n",
       "      <td>0.903657</td>\n",
       "      <td>1334000</td>\n",
       "      <td>8200</td>\n",
       "      <td>1342200</td>\n",
       "      <td>28.246138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.68</td>\n",
       "      <td>16238</td>\n",
       "      <td>27725</td>\n",
       "      <td>767</td>\n",
       "      <td>2788</td>\n",
       "      <td>0.925186</td>\n",
       "      <td>0.954896</td>\n",
       "      <td>0.853464</td>\n",
       "      <td>0.630644</td>\n",
       "      <td>0.901335</td>\n",
       "      <td>1394000</td>\n",
       "      <td>7670</td>\n",
       "      <td>1401670</td>\n",
       "      <td>29.497664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.70</td>\n",
       "      <td>16089</td>\n",
       "      <td>27784</td>\n",
       "      <td>708</td>\n",
       "      <td>2937</td>\n",
       "      <td>0.923292</td>\n",
       "      <td>0.957850</td>\n",
       "      <td>0.845632</td>\n",
       "      <td>0.633282</td>\n",
       "      <td>0.898250</td>\n",
       "      <td>1468500</td>\n",
       "      <td>7080</td>\n",
       "      <td>1475580</td>\n",
       "      <td>31.053075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.72</td>\n",
       "      <td>15940</td>\n",
       "      <td>27836</td>\n",
       "      <td>656</td>\n",
       "      <td>3086</td>\n",
       "      <td>0.921251</td>\n",
       "      <td>0.960472</td>\n",
       "      <td>0.837801</td>\n",
       "      <td>0.635874</td>\n",
       "      <td>0.894953</td>\n",
       "      <td>1543000</td>\n",
       "      <td>6560</td>\n",
       "      <td>1549560</td>\n",
       "      <td>32.609958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.74</td>\n",
       "      <td>15747</td>\n",
       "      <td>27897</td>\n",
       "      <td>595</td>\n",
       "      <td>3279</td>\n",
       "      <td>0.918473</td>\n",
       "      <td>0.963591</td>\n",
       "      <td>0.827657</td>\n",
       "      <td>0.639194</td>\n",
       "      <td>0.890466</td>\n",
       "      <td>1639500</td>\n",
       "      <td>5950</td>\n",
       "      <td>1645450</td>\n",
       "      <td>34.627930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.76</td>\n",
       "      <td>15553</td>\n",
       "      <td>27944</td>\n",
       "      <td>548</td>\n",
       "      <td>3473</td>\n",
       "      <td>0.915379</td>\n",
       "      <td>0.965965</td>\n",
       "      <td>0.817460</td>\n",
       "      <td>0.642435</td>\n",
       "      <td>0.885530</td>\n",
       "      <td>1736500</td>\n",
       "      <td>5480</td>\n",
       "      <td>1741980</td>\n",
       "      <td>36.659371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.78</td>\n",
       "      <td>15333</td>\n",
       "      <td>27990</td>\n",
       "      <td>502</td>\n",
       "      <td>3693</td>\n",
       "      <td>0.911718</td>\n",
       "      <td>0.968298</td>\n",
       "      <td>0.805897</td>\n",
       "      <td>0.646077</td>\n",
       "      <td>0.879665</td>\n",
       "      <td>1846500</td>\n",
       "      <td>5020</td>\n",
       "      <td>1851520</td>\n",
       "      <td>38.964603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.80</td>\n",
       "      <td>15107</td>\n",
       "      <td>28031</td>\n",
       "      <td>461</td>\n",
       "      <td>3919</td>\n",
       "      <td>0.907824</td>\n",
       "      <td>0.970388</td>\n",
       "      <td>0.794019</td>\n",
       "      <td>0.649798</td>\n",
       "      <td>0.873388</td>\n",
       "      <td>1959500</td>\n",
       "      <td>4610</td>\n",
       "      <td>1964110</td>\n",
       "      <td>41.334021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.82</td>\n",
       "      <td>14851</td>\n",
       "      <td>28079</td>\n",
       "      <td>413</td>\n",
       "      <td>4175</td>\n",
       "      <td>0.903447</td>\n",
       "      <td>0.972943</td>\n",
       "      <td>0.780563</td>\n",
       "      <td>0.654065</td>\n",
       "      <td>0.866200</td>\n",
       "      <td>2087500</td>\n",
       "      <td>4130</td>\n",
       "      <td>2091630</td>\n",
       "      <td>44.017635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.84</td>\n",
       "      <td>14558</td>\n",
       "      <td>28127</td>\n",
       "      <td>365</td>\n",
       "      <td>4468</td>\n",
       "      <td>0.898291</td>\n",
       "      <td>0.975541</td>\n",
       "      <td>0.765163</td>\n",
       "      <td>0.658943</td>\n",
       "      <td>0.857639</td>\n",
       "      <td>2234000</td>\n",
       "      <td>3650</td>\n",
       "      <td>2237650</td>\n",
       "      <td>47.090576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.86</td>\n",
       "      <td>14186</td>\n",
       "      <td>28179</td>\n",
       "      <td>313</td>\n",
       "      <td>4840</td>\n",
       "      <td>0.891557</td>\n",
       "      <td>0.978412</td>\n",
       "      <td>0.745611</td>\n",
       "      <td>0.665148</td>\n",
       "      <td>0.846294</td>\n",
       "      <td>2420000</td>\n",
       "      <td>3130</td>\n",
       "      <td>2423130</td>\n",
       "      <td>50.993939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.88</td>\n",
       "      <td>13759</td>\n",
       "      <td>28219</td>\n",
       "      <td>273</td>\n",
       "      <td>5267</td>\n",
       "      <td>0.883413</td>\n",
       "      <td>0.980544</td>\n",
       "      <td>0.723168</td>\n",
       "      <td>0.672233</td>\n",
       "      <td>0.832416</td>\n",
       "      <td>2633500</td>\n",
       "      <td>2730</td>\n",
       "      <td>2636230</td>\n",
       "      <td>55.478555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.90</td>\n",
       "      <td>13260</td>\n",
       "      <td>28267</td>\n",
       "      <td>225</td>\n",
       "      <td>5766</td>\n",
       "      <td>0.873921</td>\n",
       "      <td>0.983315</td>\n",
       "      <td>0.696941</td>\n",
       "      <td>0.680690</td>\n",
       "      <td>0.815724</td>\n",
       "      <td>2883000</td>\n",
       "      <td>2250</td>\n",
       "      <td>2885250</td>\n",
       "      <td>60.719096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.92</td>\n",
       "      <td>12671</td>\n",
       "      <td>28310</td>\n",
       "      <td>182</td>\n",
       "      <td>6355</td>\n",
       "      <td>0.862431</td>\n",
       "      <td>0.985840</td>\n",
       "      <td>0.665983</td>\n",
       "      <td>0.690808</td>\n",
       "      <td>0.794943</td>\n",
       "      <td>3177500</td>\n",
       "      <td>1820</td>\n",
       "      <td>3179320</td>\n",
       "      <td>66.907698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.94</td>\n",
       "      <td>11855</td>\n",
       "      <td>28344</td>\n",
       "      <td>148</td>\n",
       "      <td>7171</td>\n",
       "      <td>0.845974</td>\n",
       "      <td>0.987670</td>\n",
       "      <td>0.623095</td>\n",
       "      <td>0.705092</td>\n",
       "      <td>0.764124</td>\n",
       "      <td>3585500</td>\n",
       "      <td>1480</td>\n",
       "      <td>3586980</td>\n",
       "      <td>75.486763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.96</td>\n",
       "      <td>10688</td>\n",
       "      <td>28382</td>\n",
       "      <td>110</td>\n",
       "      <td>8338</td>\n",
       "      <td>0.822215</td>\n",
       "      <td>0.989813</td>\n",
       "      <td>0.561758</td>\n",
       "      <td>0.726440</td>\n",
       "      <td>0.716738</td>\n",
       "      <td>4169000</td>\n",
       "      <td>1100</td>\n",
       "      <td>4170100</td>\n",
       "      <td>87.758323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.98</td>\n",
       "      <td>8572</td>\n",
       "      <td>28426</td>\n",
       "      <td>66</td>\n",
       "      <td>10454</td>\n",
       "      <td>0.778610</td>\n",
       "      <td>0.992359</td>\n",
       "      <td>0.450541</td>\n",
       "      <td>0.768312</td>\n",
       "      <td>0.619722</td>\n",
       "      <td>5227000</td>\n",
       "      <td>660</td>\n",
       "      <td>5227660</td>\n",
       "      <td>110.014310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>28492</td>\n",
       "      <td>0</td>\n",
       "      <td>19026</td>\n",
       "      <td>0.599604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9513000</td>\n",
       "      <td>0</td>\n",
       "      <td>9513000</td>\n",
       "      <td>200.197820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Threshold     TP     TN     FP     FN  Accuracy  Precision  \\\n",
       "0        0.00  19026      0  28492      0  0.400396   0.400396   \n",
       "1        0.02  18929  15823  12669     97  0.731344   0.599057   \n",
       "2        0.04  18859  19299   9193    167  0.803022   0.672287   \n",
       "3        0.06  18781  21021   7471    245  0.837619   0.715412   \n",
       "4        0.08  18733  22101   6391    293  0.859338   0.745622   \n",
       "5        0.10  18667  22887   5605    359  0.874490   0.769075   \n",
       "6        0.12  18610  23495   4997    416  0.886085   0.788325   \n",
       "7        0.14  18549  24022   4470    477  0.895892   0.805813   \n",
       "8        0.16  18484  24398   4094    542  0.902437   0.818673   \n",
       "9        0.18  18408  24739   3753    618  0.908014   0.830648   \n",
       "10       0.20  18341  25019   3473    685  0.912496   0.840790   \n",
       "11       0.22  18280  25278   3214    746  0.916663   0.850470   \n",
       "12       0.24  18209  25468   3024    817  0.919167   0.857580   \n",
       "13       0.26  18136  25674   2818    890  0.921966   0.865515   \n",
       "14       0.28  18068  25852   2640    958  0.924281   0.872513   \n",
       "15       0.30  18002  26011   2481   1024  0.926238   0.878875   \n",
       "16       0.32  17932  26166   2326   1094  0.928027   0.885181   \n",
       "17       0.34  17874  26311   2181   1152  0.929858   0.891249   \n",
       "18       0.36  17818  26443   2049   1208  0.931458   0.896864   \n",
       "19       0.38  17738  26584   1908   1288  0.932741   0.902881   \n",
       "20       0.40  17664  26690   1802   1362  0.933415   0.907428   \n",
       "21       0.42  17571  26799   1693   1455  0.933751   0.912116   \n",
       "22       0.44  17490  26898   1594   1536  0.934130   0.916475   \n",
       "23       0.46  17422  26975   1517   1604  0.934320   0.919901   \n",
       "24       0.48  17337  27052   1440   1689  0.934151   0.923310   \n",
       "25       0.50  17256  27124   1368   1770  0.933962   0.926546   \n",
       "26       0.52  17182  27199   1293   1844  0.933983   0.930014   \n",
       "27       0.54  17086  27276   1216   1940  0.933583   0.933559   \n",
       "28       0.56  16982  27345   1147   2044  0.932847   0.936731   \n",
       "29       0.58  16859  27426   1066   2167  0.931963   0.940530   \n",
       "30       0.60  16746  27496    996   2280  0.931058   0.943862   \n",
       "31       0.62  16626  27554    938   2400  0.929753   0.946595   \n",
       "32       0.64  16477  27612    880   2549  0.927838   0.949300   \n",
       "33       0.66  16358  27672    820   2668  0.926596   0.952265   \n",
       "34       0.68  16238  27725    767   2788  0.925186   0.954896   \n",
       "35       0.70  16089  27784    708   2937  0.923292   0.957850   \n",
       "36       0.72  15940  27836    656   3086  0.921251   0.960472   \n",
       "37       0.74  15747  27897    595   3279  0.918473   0.963591   \n",
       "38       0.76  15553  27944    548   3473  0.915379   0.965965   \n",
       "39       0.78  15333  27990    502   3693  0.911718   0.968298   \n",
       "40       0.80  15107  28031    461   3919  0.907824   0.970388   \n",
       "41       0.82  14851  28079    413   4175  0.903447   0.972943   \n",
       "42       0.84  14558  28127    365   4468  0.898291   0.975541   \n",
       "43       0.86  14186  28179    313   4840  0.891557   0.978412   \n",
       "44       0.88  13759  28219    273   5267  0.883413   0.980544   \n",
       "45       0.90  13260  28267    225   5766  0.873921   0.983315   \n",
       "46       0.92  12671  28310    182   6355  0.862431   0.985840   \n",
       "47       0.94  11855  28344    148   7171  0.845974   0.987670   \n",
       "48       0.96  10688  28382    110   8338  0.822215   0.989813   \n",
       "49       0.98   8572  28426     66  10454  0.778610   0.992359   \n",
       "50       1.00      0  28492      0  19026  0.599604        NaN   \n",
       "\n",
       "    Recall / Sensitivity  Specificity        F1  FN_Cost  FP_Cost  Tot_Cost  \\\n",
       "0               1.000000     0.000000  0.571832        0   284920    284920   \n",
       "1               0.994902     0.455312  0.747827    48500   126690    175190   \n",
       "2               0.991223     0.505766  0.801181    83500    91930    175430   \n",
       "3               0.987123     0.528139  0.829586   122500    74710    197210   \n",
       "4               0.984600     0.541240  0.848607   146500    63910    210410   \n",
       "5               0.981131     0.550777  0.862257   179500    56050    235550   \n",
       "6               0.978135     0.558010  0.873033   208000    49970    257970   \n",
       "7               0.974929     0.564281  0.882340   238500    44700    283200   \n",
       "8               0.971513     0.568957  0.888568   271000    40940    311940   \n",
       "9               0.967518     0.573365  0.893874   309000    37530    346530   \n",
       "10              0.963997     0.577006  0.898188   342500    34730    377230   \n",
       "11              0.960790     0.580330  0.902270   373000    32140    405140   \n",
       "12              0.957059     0.583099  0.904593   408500    30240    438740   \n",
       "13              0.953222     0.586031  0.907254   445000    28180    473180   \n",
       "14              0.949648     0.588616  0.909448   479000    26400    505400   \n",
       "15              0.946179     0.590984  0.911286   512000    24810    536810   \n",
       "16              0.942500     0.593360  0.912942   547000    23260    570260   \n",
       "17              0.939451     0.595474  0.914716   576000    21810    597810   \n",
       "18              0.936508     0.597433  0.916257   604000    20490    624490   \n",
       "19              0.932303     0.599792  0.917356   644000    19080    663080   \n",
       "20              0.928414     0.601750  0.917801   681000    18020    699020   \n",
       "21              0.923526     0.603989  0.917785   727500    16930    744430   \n",
       "22              0.919268     0.605975  0.917869   768000    15940    783940   \n",
       "23              0.915694     0.607586  0.917793   802000    15170    817170   \n",
       "24              0.911227     0.609430  0.917229   844500    14400    858900   \n",
       "25              0.906969     0.611176  0.916653   885000    13680    898680   \n",
       "26              0.903080     0.612852  0.916349   922000    12930    934930   \n",
       "27              0.898034     0.614851  0.915452   970000    12160    982160   \n",
       "28              0.892568     0.616893  0.914117  1022000    11470   1033470   \n",
       "29              0.886103     0.619307  0.912506  1083500    10660   1094160   \n",
       "30              0.880164     0.621491  0.910901  1140000     9960   1149960   \n",
       "31              0.873857     0.623676  0.908773  1200000     9380   1209380   \n",
       "32              0.866025     0.626279  0.905753  1274500     8800   1283300   \n",
       "33              0.859771     0.628481  0.903657  1334000     8200   1342200   \n",
       "34              0.853464     0.630644  0.901335  1394000     7670   1401670   \n",
       "35              0.845632     0.633282  0.898250  1468500     7080   1475580   \n",
       "36              0.837801     0.635874  0.894953  1543000     6560   1549560   \n",
       "37              0.827657     0.639194  0.890466  1639500     5950   1645450   \n",
       "38              0.817460     0.642435  0.885530  1736500     5480   1741980   \n",
       "39              0.805897     0.646077  0.879665  1846500     5020   1851520   \n",
       "40              0.794019     0.649798  0.873388  1959500     4610   1964110   \n",
       "41              0.780563     0.654065  0.866200  2087500     4130   2091630   \n",
       "42              0.765163     0.658943  0.857639  2234000     3650   2237650   \n",
       "43              0.745611     0.665148  0.846294  2420000     3130   2423130   \n",
       "44              0.723168     0.672233  0.832416  2633500     2730   2636230   \n",
       "45              0.696941     0.680690  0.815724  2883000     2250   2885250   \n",
       "46              0.665983     0.690808  0.794943  3177500     1820   3179320   \n",
       "47              0.623095     0.705092  0.764124  3585500     1480   3586980   \n",
       "48              0.561758     0.726440  0.716738  4169000     1100   4170100   \n",
       "49              0.450541     0.768312  0.619722  5227000      660   5227660   \n",
       "50              0.000000     1.000000       NaN  9513000        0   9513000   \n",
       "\n",
       "    Cost_per_Obs  \n",
       "0       5.996044  \n",
       "1       3.686813  \n",
       "2       3.691864  \n",
       "3       4.150217  \n",
       "4       4.428006  \n",
       "5       4.957069  \n",
       "6       5.428890  \n",
       "7       5.959847  \n",
       "8       6.564670  \n",
       "9       7.292605  \n",
       "10      7.938676  \n",
       "11      8.526032  \n",
       "12      9.233133  \n",
       "13      9.957911  \n",
       "14     10.635970  \n",
       "15     11.296982  \n",
       "16     12.000926  \n",
       "17     12.580706  \n",
       "18     13.142178  \n",
       "19     13.954291  \n",
       "20     14.710636  \n",
       "21     15.666274  \n",
       "22     16.497748  \n",
       "23     17.197062  \n",
       "24     18.075256  \n",
       "25     18.912412  \n",
       "26     19.675281  \n",
       "27     20.669220  \n",
       "28     21.749021  \n",
       "29     23.026222  \n",
       "30     24.200513  \n",
       "31     25.450987  \n",
       "32     27.006608  \n",
       "33     28.246138  \n",
       "34     29.497664  \n",
       "35     31.053075  \n",
       "36     32.609958  \n",
       "37     34.627930  \n",
       "38     36.659371  \n",
       "39     38.964603  \n",
       "40     41.334021  \n",
       "41     44.017635  \n",
       "42     47.090576  \n",
       "43     50.993939  \n",
       "44     55.478555  \n",
       "45     60.719096  \n",
       "46     66.907698  \n",
       "47     75.486763  \n",
       "48     87.758323  \n",
       "49    110.014310  \n",
       "50    200.197820  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thresh = getThreshold(Y_test,xgb_c.predict_proba(X_test),pos_label=1)\n",
    "df_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-bb188d2c705344488d6a0958f4806a20\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-bb188d2c705344488d6a0958f4806a20\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-bb188d2c705344488d6a0958f4806a20\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"line\", \"color\": \"#fc030f\"}, \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"Threshold\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"Accuracy\"}}}, {\"mark\": {\"type\": \"line\", \"color\": \"#136e1a\"}, \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"Threshold\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"Precision\"}}}, {\"mark\": {\"type\": \"line\", \"color\": \"#3a3b9c\"}, \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"Threshold\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"Recall / Sensitivity\"}}}, {\"mark\": {\"type\": \"line\", \"color\": \"#ebac00\"}, \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"Threshold\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"Specificity\"}}}, {\"mark\": \"rule\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"opt\"}}}], \"data\": {\"name\": \"data-c63dc66376d0695668acf7421bcd56da\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-c63dc66376d0695668acf7421bcd56da\": [{\"Threshold\": 0.0, \"TP\": 19026, \"TN\": 0, \"FP\": 28492, \"FN\": 0, \"Accuracy\": 0.400395639547119, \"Precision\": 0.400395639547119, \"Recall / Sensitivity\": 1.0, \"Specificity\": 0.0, \"F1\": 0.5718321711949989, \"opt\": 0.45}, {\"Threshold\": 0.02, \"TP\": 18929, \"TN\": 15823, \"FP\": 12669, \"FN\": 97, \"Accuracy\": 0.7313439117807988, \"Precision\": 0.5990569023355908, \"Recall / Sensitivity\": 0.9949017134447597, \"Specificity\": 0.45531192449355434, \"F1\": 0.7478271175726928, \"opt\": 0.45}, {\"Threshold\": 0.04, \"TP\": 18859, \"TN\": 19299, \"FP\": 9193, \"FN\": 167, \"Accuracy\": 0.8030220127109727, \"Precision\": 0.6722871809496649, \"Recall / Sensitivity\": 0.9912225375801534, \"Specificity\": 0.5057655013365481, \"F1\": 0.8011810187348656, \"opt\": 0.45}, {\"Threshold\": 0.06, \"TP\": 18781, \"TN\": 21021, \"FP\": 7471, \"FN\": 245, \"Accuracy\": 0.8376194284271223, \"Precision\": 0.7154121590735943, \"Recall / Sensitivity\": 0.9871228844738779, \"Specificity\": 0.5281392894829405, \"F1\": 0.8295861124607977, \"opt\": 0.45}, {\"Threshold\": 0.08, \"TP\": 18733, \"TN\": 22101, \"FP\": 6391, \"FN\": 293, \"Accuracy\": 0.8593375142051433, \"Precision\": 0.7456217162872154, \"Recall / Sensitivity\": 0.9846000210238621, \"Specificity\": 0.5412401430180732, \"F1\": 0.8486070215175539, \"opt\": 0.45}, {\"Threshold\": 0.1, \"TP\": 18667, \"TN\": 22887, \"FP\": 5605, \"FN\": 359, \"Accuracy\": 0.87448966707353, \"Precision\": 0.7690754779169413, \"Recall / Sensitivity\": 0.9811310837800904, \"Specificity\": 0.5507773018241324, \"F1\": 0.8622569171786226, \"opt\": 0.45}, {\"Threshold\": 0.12, \"TP\": 18610, \"TN\": 23495, \"FP\": 4997, \"FN\": 416, \"Accuracy\": 0.8860852729491981, \"Precision\": 0.7883254966747151, \"Recall / Sensitivity\": 0.9781351834331967, \"Specificity\": 0.5580097375608598, \"F1\": 0.8730326273074849, \"opt\": 0.45}, {\"Threshold\": 0.14, \"TP\": 18549, \"TN\": 24022, \"FP\": 4470, \"FN\": 477, \"Accuracy\": 0.8958920830001262, \"Precision\": 0.8058125895998958, \"Recall / Sensitivity\": 0.9749290444654684, \"Specificity\": 0.5642808484649174, \"F1\": 0.8823403496254014, \"opt\": 0.45}, {\"Threshold\": 0.16, \"TP\": 18484, \"TN\": 24398, \"FP\": 4094, \"FN\": 542, \"Accuracy\": 0.9024369712529988, \"Precision\": 0.818673044556648, \"Recall / Sensitivity\": 0.9715126668769053, \"Specificity\": 0.5689566717970244, \"F1\": 0.8885684068839534, \"opt\": 0.45}, {\"Threshold\": 0.18, \"TP\": 18408, \"TN\": 24739, \"FP\": 3753, \"FN\": 618, \"Accuracy\": 0.9080138052948357, \"Precision\": 0.8306484364423988, \"Recall / Sensitivity\": 0.967518133081047, \"Specificity\": 0.5733654715275686, \"F1\": 0.8938742807196445, \"opt\": 0.45}, {\"Threshold\": 0.2, \"TP\": 18341, \"TN\": 25019, \"FP\": 3473, \"FN\": 685, \"Accuracy\": 0.9124963171850667, \"Precision\": 0.840790318144311, \"Recall / Sensitivity\": 0.9639966361820667, \"Specificity\": 0.5770064575645757, \"F1\": 0.8981880509304604, \"opt\": 0.45}, {\"Threshold\": 0.22, \"TP\": 18280, \"TN\": 25278, \"FP\": 3214, \"FN\": 746, \"Accuracy\": 0.9166631592238731, \"Precision\": 0.8504698985763469, \"Recall / Sensitivity\": 0.9607904972143383, \"Specificity\": 0.5803296753753616, \"F1\": 0.9022704837117473, \"opt\": 0.45}, {\"Threshold\": 0.24, \"TP\": 18209, \"TN\": 25468, \"FP\": 3024, \"FN\": 817, \"Accuracy\": 0.9191674733785092, \"Precision\": 0.8575801817924928, \"Recall / Sensitivity\": 0.9570587616945233, \"Specificity\": 0.5830986560432264, \"F1\": 0.9045927618669118, \"opt\": 0.45}, {\"Threshold\": 0.26, \"TP\": 18136, \"TN\": 25674, \"FP\": 2818, \"FN\": 890, \"Accuracy\": 0.9219664127278084, \"Precision\": 0.8655149374821036, \"Recall / Sensitivity\": 0.953221906864291, \"Specificity\": 0.5860305866240584, \"F1\": 0.9072536268134067, \"opt\": 0.45}, {\"Threshold\": 0.28, \"TP\": 18068, \"TN\": 25852, \"FP\": 2640, \"FN\": 958, \"Accuracy\": 0.9242813249715898, \"Precision\": 0.8725130384392505, \"Recall / Sensitivity\": 0.949647850310102, \"Specificity\": 0.588615664845173, \"F1\": 0.9094478280565762, \"opt\": 0.45}, {\"Threshold\": 0.3, \"TP\": 18002, \"TN\": 26011, \"FP\": 2481, \"FN\": 1024, \"Accuracy\": 0.926238478050423, \"Precision\": 0.8788751647707855, \"Recall / Sensitivity\": 0.9461789130663303, \"Specificity\": 0.590984481857633, \"F1\": 0.911286036093042, \"opt\": 0.45}, {\"Threshold\": 0.32, \"TP\": 17932, \"TN\": 26166, \"FP\": 2326, \"FN\": 1094, \"Accuracy\": 0.9280272738751632, \"Precision\": 0.8851811629973344, \"Recall / Sensitivity\": 0.942499737201724, \"Specificity\": 0.593360243094925, \"F1\": 0.9129416556358823, \"opt\": 0.45}, {\"Threshold\": 0.34, \"TP\": 17874, \"TN\": 26311, \"FP\": 2181, \"FN\": 1152, \"Accuracy\": 0.9298581590134265, \"Precision\": 0.8912490650710546, \"Recall / Sensitivity\": 0.9394512771996215, \"Specificity\": 0.5954735770057712, \"F1\": 0.9147155906962463, \"opt\": 0.45}, {\"Threshold\": 0.36, \"TP\": 17818, \"TN\": 26443, \"FP\": 2049, \"FN\": 1208, \"Accuracy\": 0.9314575529273118, \"Precision\": 0.8968641465747219, \"Recall / Sensitivity\": 0.9365079365079365, \"Specificity\": 0.5974334063848535, \"F1\": 0.9162574242151544, \"opt\": 0.45}, {\"Threshold\": 0.38, \"TP\": 17738, \"TN\": 26584, \"FP\": 1908, \"FN\": 1288, \"Accuracy\": 0.9327412769897723, \"Precision\": 0.9028809935864807, \"Recall / Sensitivity\": 0.9323031640912436, \"Specificity\": 0.5997924281395244, \"F1\": 0.917356226727348, \"opt\": 0.45}, {\"Threshold\": 0.4, \"TP\": 17664, \"TN\": 26690, \"FP\": 1802, \"FN\": 1362, \"Accuracy\": 0.9334147060061451, \"Precision\": 0.9074283365868694, \"Recall / Sensitivity\": 0.9284137496058026, \"Specificity\": 0.6017495603553231, \"F1\": 0.9178011015275901, \"opt\": 0.45}, {\"Threshold\": 0.42, \"TP\": 17571, \"TN\": 26799, \"FP\": 1693, \"FN\": 1455, \"Accuracy\": 0.9337514205143315, \"Precision\": 0.9121158637873754, \"Recall / Sensitivity\": 0.923525701671397, \"Specificity\": 0.6039891818796485, \"F1\": 0.9177853225385217, \"opt\": 0.45}, {\"Threshold\": 0.44, \"TP\": 17490, \"TN\": 26898, \"FP\": 1594, \"FN\": 1536, \"Accuracy\": 0.9341302243360411, \"Precision\": 0.9164745336407462, \"Recall / Sensitivity\": 0.9192683695994954, \"Specificity\": 0.6059745877264126, \"F1\": 0.917869325636316, \"opt\": 0.45}, {\"Threshold\": 0.46, \"TP\": 17422, \"TN\": 26975, \"FP\": 1517, \"FN\": 1604, \"Accuracy\": 0.9343196262468959, \"Precision\": 0.9199007339352658, \"Recall / Sensitivity\": 0.9156943130453065, \"Specificity\": 0.6075860981597856, \"F1\": 0.9177927038061372, \"opt\": 0.45}, {\"Threshold\": 0.48, \"TP\": 17337, \"TN\": 27052, \"FP\": 1440, \"FN\": 1689, \"Accuracy\": 0.9341512689928028, \"Precision\": 0.9233104329765138, \"Recall / Sensitivity\": 0.9112267423525702, \"Specificity\": 0.6094302642546577, \"F1\": 0.9172287913657646, \"opt\": 0.45}, {\"Threshold\": 0.5, \"TP\": 17256, \"TN\": 27124, \"FP\": 1368, \"FN\": 1770, \"Accuracy\": 0.9339618670819478, \"Precision\": 0.9265463917525774, \"Recall / Sensitivity\": 0.9069694102806686, \"Specificity\": 0.611176205497972, \"F1\": 0.9166533864541833, \"opt\": 0.45}, {\"Threshold\": 0.52, \"TP\": 17182, \"TN\": 27199, \"FP\": 1293, \"FN\": 1844, \"Accuracy\": 0.9339829117387095, \"Precision\": 0.9300135317997293, \"Recall / Sensitivity\": 0.9030799957952276, \"Specificity\": 0.6128523467249498, \"F1\": 0.9163488973627371, \"opt\": 0.45}, {\"Threshold\": 0.54, \"TP\": 17086, \"TN\": 27276, \"FP\": 1216, \"FN\": 1940, \"Accuracy\": 0.9335830632602382, \"Precision\": 0.9335591738607802, \"Recall / Sensitivity\": 0.898034268895196, \"Specificity\": 0.6148505477661061, \"F1\": 0.9154522074582084, \"opt\": 0.45}, {\"Threshold\": 0.56, \"TP\": 16982, \"TN\": 27345, \"FP\": 1147, \"FN\": 2044, \"Accuracy\": 0.9328465002735805, \"Precision\": 0.9367312041480501, \"Recall / Sensitivity\": 0.8925680647534953, \"Specificity\": 0.6168926387980238, \"F1\": 0.9141165388238461, \"opt\": 0.45}, {\"Threshold\": 0.58, \"TP\": 16859, \"TN\": 27426, \"FP\": 1066, \"FN\": 2167, \"Accuracy\": 0.9319626246895913, \"Precision\": 0.9405299860529986, \"Recall / Sensitivity\": 0.8861032271628299, \"Specificity\": 0.6193067630123067, \"F1\": 0.912505750859246, \"opt\": 0.45}, {\"Threshold\": 0.6, \"TP\": 16746, \"TN\": 27496, \"FP\": 996, \"FN\": 2280, \"Accuracy\": 0.9310577044488404, \"Precision\": 0.9438620223199189, \"Recall / Sensitivity\": 0.8801639861242511, \"Specificity\": 0.6214908910085439, \"F1\": 0.9109007832898173, \"opt\": 0.45}, {\"Threshold\": 0.62, \"TP\": 16626, \"TN\": 27554, \"FP\": 938, \"FN\": 2400, \"Accuracy\": 0.9297529357296183, \"Precision\": 0.9465953085857436, \"Recall / Sensitivity\": 0.8738568274992116, \"Specificity\": 0.6236758714350384, \"F1\": 0.9087728887674227, \"opt\": 0.45}, {\"Threshold\": 0.64, \"TP\": 16477, \"TN\": 27612, \"FP\": 880, \"FN\": 2549, \"Accuracy\": 0.9278378719643082, \"Precision\": 0.9492999942386358, \"Recall / Sensitivity\": 0.866025438873121, \"Specificity\": 0.6262786636122388, \"F1\": 0.9057526866943353, \"opt\": 0.45}, {\"Threshold\": 0.66, \"TP\": 16358, \"TN\": 27672, \"FP\": 820, \"FN\": 2668, \"Accuracy\": 0.926596237215371, \"Precision\": 0.9522645243916638, \"Recall / Sensitivity\": 0.8597708399032903, \"Specificity\": 0.6284805814217579, \"F1\": 0.9036570544691195, \"opt\": 0.45}, {\"Threshold\": 0.68, \"TP\": 16238, \"TN\": 27725, \"FP\": 767, \"FN\": 2788, \"Accuracy\": 0.9251862452123406, \"Precision\": 0.9548956189356071, \"Recall / Sensitivity\": 0.8534636812782508, \"Specificity\": 0.6306439505948184, \"F1\": 0.901334961560878, \"opt\": 0.45}, {\"Threshold\": 0.7000000000000001, \"TP\": 16089, \"TN\": 27784, \"FP\": 708, \"FN\": 2937, \"Accuracy\": 0.9232922261037922, \"Precision\": 0.9578496160028577, \"Recall / Sensitivity\": 0.8456322926521602, \"Specificity\": 0.6332824288286646, \"F1\": 0.89824972782849, \"opt\": 0.45}, {\"Threshold\": 0.72, \"TP\": 15940, \"TN\": 27836, \"FP\": 656, \"FN\": 3086, \"Accuracy\": 0.9212508943979124, \"Precision\": 0.960472402988672, \"Recall / Sensitivity\": 0.8378009040260695, \"Specificity\": 0.6358735380116959, \"F1\": 0.8949525574083431, \"opt\": 0.45}, {\"Threshold\": 0.74, \"TP\": 15747, \"TN\": 27897, \"FP\": 595, \"FN\": 3279, \"Accuracy\": 0.9184729997053748, \"Precision\": 0.9635907477664912, \"Recall / Sensitivity\": 0.8276568905707978, \"Specificity\": 0.6391943909815783, \"F1\": 0.8904659579280705, \"opt\": 0.45}, {\"Threshold\": 0.76, \"TP\": 15553, \"TN\": 27944, \"FP\": 548, \"FN\": 3473, \"Accuracy\": 0.9153794351614125, \"Precision\": 0.965964846903919, \"Recall / Sensitivity\": 0.8174603174603174, \"Specificity\": 0.6424351104673885, \"F1\": 0.8855296495573206, \"opt\": 0.45}, {\"Threshold\": 0.78, \"TP\": 15333, \"TN\": 27990, \"FP\": 502, \"FN\": 3693, \"Accuracy\": 0.9117176648848857, \"Precision\": 0.9682980738869593, \"Recall / Sensitivity\": 0.8058971933144119, \"Specificity\": 0.6460771414721972, \"F1\": 0.8796649551074267, \"opt\": 0.45}, {\"Threshold\": 0.8, \"TP\": 15107, \"TN\": 28031, \"FP\": 461, \"FN\": 3919, \"Accuracy\": 0.9078244033839808, \"Precision\": 0.9703879753340185, \"Recall / Sensitivity\": 0.7940187112372543, \"Specificity\": 0.649798321665353, \"F1\": 0.8733884488639649, \"opt\": 0.45}, {\"Threshold\": 0.8200000000000001, \"TP\": 14851, \"TN\": 28079, \"FP\": 413, \"FN\": 4175, \"Accuracy\": 0.903447114777558, \"Precision\": 0.9729428721174004, \"Recall / Sensitivity\": 0.7805634395038369, \"Specificity\": 0.6540647565804798, \"F1\": 0.8662000583260425, \"opt\": 0.45}, {\"Threshold\": 0.84, \"TP\": 14558, \"TN\": 28127, \"FP\": 365, \"FN\": 4468, \"Accuracy\": 0.8982911738709541, \"Precision\": 0.9755411110366549, \"Recall / Sensitivity\": 0.7651634605276989, \"Specificity\": 0.658943422748038, \"F1\": 0.8576394002768859, \"opt\": 0.45}, {\"Threshold\": 0.86, \"TP\": 14186, \"TN\": 28179, \"FP\": 313, \"FN\": 4840, \"Accuracy\": 0.8915568837072267, \"Precision\": 0.9784123042968481, \"Recall / Sensitivity\": 0.7456112687900768, \"Specificity\": 0.6651481175498642, \"F1\": 0.8462938105891126, \"opt\": 0.45}, {\"Threshold\": 0.88, \"TP\": 13759, \"TN\": 28219, \"FP\": 273, \"FN\": 5267, \"Accuracy\": 0.8834126015404689, \"Precision\": 0.9805444697833523, \"Recall / Sensitivity\": 0.7231682960159781, \"Specificity\": 0.6722330744675783, \"F1\": 0.8324157541291064, \"opt\": 0.45}, {\"Threshold\": 0.9, \"TP\": 13260, \"TN\": 28267, \"FP\": 225, \"FN\": 5766, \"Accuracy\": 0.8739214613409655, \"Precision\": 0.9833147942157954, \"Recall / Sensitivity\": 0.6969410280668559, \"Specificity\": 0.6806896717798059, \"F1\": 0.8157239088308573, \"opt\": 0.45}, {\"Threshold\": 0.92, \"TP\": 12671, \"TN\": 28310, \"FP\": 182, \"FN\": 6355, \"Accuracy\": 0.8624310787491056, \"Precision\": 0.9858398817396716, \"Recall / Sensitivity\": 0.6659833911489541, \"Specificity\": 0.6908079353846904, \"F1\": 0.7949433796543179, \"opt\": 0.45}, {\"Threshold\": 0.9400000000000001, \"TP\": 11855, \"TN\": 28344, \"FP\": 148, \"FN\": 7171, \"Accuracy\": 0.8459741571614967, \"Precision\": 0.9876697492293594, \"Recall / Sensitivity\": 0.623094712498686, \"Specificity\": 0.7050921664718027, \"F1\": 0.7641238841084147, \"opt\": 0.45}, {\"Threshold\": 0.96, \"TP\": 10688, \"TN\": 28382, \"FP\": 110, \"FN\": 8338, \"Accuracy\": 0.8222147396775958, \"Precision\": 0.9898129283200593, \"Recall / Sensitivity\": 0.5617575948701776, \"Specificity\": 0.726439723573074, \"F1\": 0.7167381974248928, \"opt\": 0.45}, {\"Threshold\": 0.98, \"TP\": 8572, \"TN\": 28426, \"FP\": 66, \"FN\": 10454, \"Accuracy\": 0.7786102108674607, \"Precision\": 0.9923593424403797, \"Recall / Sensitivity\": 0.45054136444864923, \"Specificity\": 0.7683118006378723, \"F1\": 0.6197223828802776, \"opt\": 0.45}, {\"Threshold\": 1.0, \"TP\": 0, \"TN\": 28492, \"FP\": 0, \"FN\": 19026, \"Accuracy\": 0.599604360452881, \"Precision\": null, \"Recall / Sensitivity\": 0.0, \"Specificity\": 1.0, \"F1\": null, \"opt\": 0.45}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = df_thresh\n",
    "source['opt'] = .45\n",
    "\n",
    "base = alt.Chart(source)\n",
    "\n",
    "#red\n",
    "acc= base.mark_line(color=\"#fc030f\").encode(\n",
    "    x='Threshold:Q',\n",
    "    y='Accuracy:Q'\n",
    ")\n",
    "#green\n",
    "prec = base.mark_line(color=\"#136e1a\").encode(\n",
    "    x='Threshold:Q',\n",
    "    y='Precision:Q'\n",
    ")\n",
    "#blue\n",
    "rec = base.mark_line(color=\"#3a3b9c\").encode(\n",
    "    x='Threshold:Q',\n",
    "    y='Recall / Sensitivity:Q'\n",
    ")\n",
    "#orange\n",
    "spec = base.mark_line(color=\"#ebac00\").encode(\n",
    "    x='Threshold:Q',\n",
    "    y='Specificity:Q'\n",
    ")\n",
    "\n",
    "optimal = base.mark_rule().encode(\n",
    "    x='opt'\n",
    ")\n",
    "acc+prec+rec+spec+optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#.45 threshold has highest precision and accuracy\n",
    "proba = xgb_c.predict_proba(X_test)\n",
    "threshold_predict = np.where(proba[:,1] > .45,1,0)\n",
    "threshold_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95     28492\n",
      "           1       0.92      0.92      0.92     19026\n",
      "\n",
      "    accuracy                           0.93     47518\n",
      "   macro avg       0.93      0.93      0.93     47518\n",
      "weighted avg       0.93      0.93      0.93     47518\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Compute precision, recall, F-measure and support\n",
    "print(classification_report(Y_test,threshold_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive: 17452\n",
      "False Positive: 1557\n",
      "False Negative: 1574\n",
      "True Negative: 26935\n",
      "=======================\n",
      "Accuracy: 0.9341091796792794\n",
      "TPR: 0.9172711027015663\n",
      "FPR: 0.05464691843324442\n",
      "Precision: 0.9180914303750854\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(Y_test,threshold_predict).ravel()\n",
    "print(\"True Positive: {}\".format(tp))\n",
    "print(\"False Positive: {}\".format(fp))\n",
    "print(\"False Negative: {}\".format(fn))\n",
    "print(\"True Negative: {}\".format(tn))\n",
    "print(\"=======================\")\n",
    "print(\"Accuracy: {}\".format((tp+tn)/(tp+tn+fp+fn)))\n",
    "print(\"TPR: {}\".format(tp/(tp+fn)))\n",
    "print(\"FPR: {}\".format(fp/(fp+tn)))\n",
    "print(\"Precision: {}\".format(tp/(tp+fp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost of False Positives: $15570\n",
      "Cost of False Negatives: $787000\n",
      "Total Cost: $802570\n"
     ]
    }
   ],
   "source": [
    "fp_cost = fp*10\n",
    "fn_cost = fn*500\n",
    "print(\"Cost of False Positives: ${}\".format(fp_cost))\n",
    "print(\"Cost of False Negatives: ${}\".format(fn_cost))\n",
    "print(\"Total Cost: ${}\".format(fp_cost+fn_cost))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
