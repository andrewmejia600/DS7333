---
title: "Case_Study_4_Code"
author: "Brian Gaither, Sean Mcwhirter, Andrew Mejia, Sabrina Purvis"
date: "`r Sys.time()`"
output:
  html_document:
    toc: yes
    toc_float: yes
    toc_depth: 6
  github_document:
    toc: yes
    toc_depth: 6
  word_document:
    toc: yes
    toc_depth: '6'
always_allow_html: yes
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(tidyverse)
library(hms)
library(rvest)
library(lubridate)
library(foreach)
library(stringr)
library(iterators)
library(progress)
library(doParallel)
library(doSNOW)
library(dplyr)
library(ggplot2)
library(hexbin)
```

```{r}
years = c(1999:2012)
division = 'Overall+Women'
section = '10M' 
sex = 'W'
```

#### Functions

#The gen_Link function will generates the link with the query parameters for the searchable database

```{r}
gen_Link = function(year,division,section,page=1,sex){

  paste0( 'http://www.cballtimeresults.org/performances'
          ,'?division=',division,'&page=',page,
          '&section=',section, '&sex=',sex, 
          '&utf8=%E2%9C%93','&year=',year)
          #,'?utf8=%E2%9C%93&section=',section
          #,'&year=',year,'&division=',division,'&page=', page)

}

```

# The gen_Table function will parse through the table of 20 records and 15 observations
# and parse the table into its own data frame from xml2 read)html function and then use 
# the pipe operator to use rvest nodes to find the table structure 
# then the fucntion will insert the metadata for the query parameters of year, division, section, page, source link and sex 
```{r}
gen_Table = function(year,division,section,page, sex){
  
  
  #use gen_link function to get link to page 
  genlink=gen_Link(year,division,section,page=page, sex=sex)
  
  #read the page, and grab to 'table' tag
  single_table = xml2::read_html(genlink) %>% 
    rvest::html_nodes("table")  %>% 
    rvest::html_table(fill=TRUE) 
  
  #get the table and add metadata for the query parameters
  table_out = single_table[[1]] %>% 
    mutate(year=year, divisionTitle=division, section=section, page=page, source=genlink, sex = sex)
  
}

```

# This function will use all available cores on machine
# It will process the years in parrell. 
```{r}
# This code has been adapted from 
# https://github.com/ngupta23/ds7333_qtw/blob/master/case_study_2/submission_Kannan_Moro_Gupta/code/CS2_ETL.Rmd 
# https://cran.r-project.org/web/packages/doSNOW/doSNOW.pdf
# https://stackoverflow.com/questions/36794063/r-foreach-from-single-machine-to-cluster
# https://cran.r-project.org/web/packages/progress/progress.pdf
# https://www.r-bloggers.com/2013/08/the-wonders-of-foreach/
```


```{r}
scrapeTables  = function(years,division,section, sex,  max_itr = 500){
  
  
library(progress)
library(doParallel)
library(doSNOW)  
  
    #Initialize Parrellel Process to detect number of cores 
    #https://cran.r-project.org/web/packages/doSNOW/doSNOW.pdf
    #https://stackoverflow.com/questions/36794063/r-foreach-from-single-machine-to-cluster
  
    #Generate and register initial clusters based on cores, otherwise, this is a long process 
    cl = makeCluster(detectCores())
    doSNOW::registerDoSNOW(cl)
    
    #Generate progress bar for the parallel loop based on number of years 
    #https://cran.r-project.org/web/packages/progress/progress.pdf
    progBar = progress::progress_bar$new(total = length(years),format='[:bar] :percent :eta')
    progress = function(n) progBar$tick()
    
    #Initialize a parallel loop per each year
    #Intialize tableRaw as empty to loop to be populated as a table dataframe from gen_Table function
    tableRaw=NULL
    
    #tableRaw will now use for each using years as the iterator to use .combine to rbind
    #.export will do the gen_Table and gen_Link functions simultanlously and 
    #options.snow will show the progress bar
    # the %dopar% will process all the years simultaneously. 
    #https://www.r-bloggers.com/2013/08/the-wonders-of-foreach/
    tableRaw = foreach(y=years
                      ,.combine=rbind,.export=c('gen_Table','gen_Link')
                      ,.options.snow = list(progress=progress)) %dopar%
      {
        
        library(foreach)
        library(dplyr)
        #intialize isCompleted variable as FALSE for bool conditions to see if loop has been completed
        isCompleted=FALSE
        
        #Initiate loop since most pages are 487, we will only loop for the iterations for max_itr
        tableRaw=foreach(p=c(1:max_itr),.combine=rbind) %do% 
          if(!isCompleted) {
            message('getting year:',y, ' page:',p,appendLF = F)
            #get the table of the current page
            table = gen_Table(year=y
                             ,division=division
                             ,section=section
                             ,page=p
                             ,sex=sex)
            message(' rows:',nrow(table))
            isCompleted = nrow(table)==0 #if there is record, we are at the last page, no need to read further
            return(table)
          }
        return(tableRaw)
      }
    #Deactivate the cluster of cores
    stopCluster(cl)
    #save the raw data to rda format for later processing based on gender
    saveRDS(tableRaw,file=paste0('CB',sex,'tableRaw.rda'))
    
  return(tableRaw)
}
  
 
```


```{r}
Women_table = scrapeTables(years=years,division = division,section=section,sex = sex, max_itr = 500)
```

```{r}
head(Women_table)
```

```{r}
dfWomen = transform(Women_table, Race = as.factor(Race),Age = as.integer(Age), Hometown = as.factor(Hometown), year = as.factor(year) )
head(dfWomen)
```
```{r}
summary(dfWomen)
```
We evaluate how many null values are in Age = 20 null ages
```{r}
print(dim(dfWomen[is.na(dfWomen$Age),])[1])
```

Upon examining the null age records, it doesn't appear to be a data ingestion issue, we'll drop these records
```{r}
dfWomen %>% filter(is.na(Age))
```
Dropping the 20 records with null ages as it's not going to help our analysis
```{r}
dfWomen = dfWomen %>% filter(!is.na(Age))
```

```{r}
f = ggplot(dfWomen)
f + geom_boxplot(mapping = aes(x=year, y=Age)) + theme_classic() + labs(title="Boxplot of Age by Year")

```
Let's take a look at the one runner with the low age in 2009, it appears to be legitimate
```{r}
dfWomen %>% filter(Age < 10)
```

Next, we need to convert Time into minutes
```{r}
#first, separate time into three different columns (h, m, ss)
df = dfWomen
df = separate(df, Time, c("Hours","Minutes","Seconds"),":", remove=FALSE, convert=TRUE, fill="warn")
head(df)
```

```{r}
df$TimeMinutes = (df$Hours * 60) + df$Minutes + (df$Seconds/60)
head(df)
```


```{r}
ggplot(df, aes(x = Age, y=TimeMinutes)) + 
  geom_hex() +
  theme_bw() + 
  labs(title="Scatter Plot of Female Runners:  Age vs Time in Minutes")

```

```{r}
df$AgeBin = cut(df$Age, breaks=c(0,5,15,25,35,45,55,65,75,85,95),labels=c("1-5","6-15","16-25","26-35","36-45","46-55","56-65","66-75","76-85","86-95"))
head(df)
```

Let's take a look at age groups and their relationship to running time
```{r}
f = ggplot(df)
f + geom_boxplot(mapping = aes(x=AgeBin, y=TimeMinutes)) + theme_classic() + labs(title="Boxplot of Age Group by Running Time (Minutes)")
```
Let's fit a linear regression model looking at running time as a function of age.  The lm function performs least squares to find the best fitting line to our data
```{r}
lmAge = lm(TimeMinutes ~ Age, data = df)
lmAge$coefficients
```

```{r}
summary(lmAge)
```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```


